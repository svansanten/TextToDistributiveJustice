{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:10:54.094955Z",
     "end_time": "2024-06-05T11:10:54.413993Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import difflib\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# B4 Principle, Topic, Unit, Shape\n",
    "\n",
    "## Notebook to evaluate GPT-annotate results\n",
    "\n",
    "Codebooks:\n",
    "- B4.0: zero shot\n",
    "\n",
    "Test for 5 different seeds [3644,3441, 280, 5991, 7917]\n",
    "> Refer to these as S1-5\n",
    "\n",
    "Batch of 20 sentences\n",
    "1 Iteration.\n",
    "\n",
    "Main outcomes: T0 - I1\n",
    "For testing purposes: (T 0.6 I1 - T 0 I3)\n",
    "\n",
    "FINGERPRINT USED: fp_319be4768e\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Basic stats of train dataset:\n",
    "HLS_train = pd.read_csv('data/string/HLS_train_string.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:10:54.852496Z",
     "end_time": "2024-06-05T11:10:54.899832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "not evaluated                  992\nprioritarian                    66\nutilitarian                     59\negalitarian                     52\ngeneral normative statement     34\nsufficientarian                  8\nlibertarian                      1\nName: PRINCIPLE, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HLS_train['PRINCIPLE'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:10:55.258756Z",
     "end_time": "2024-06-05T11:10:55.309071Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Results B4.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Import Results\n",
    "Results created under the same fingerprint are saved in a CSV file for each seed. All results are combined into one dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "#B1.0\n",
    "path_B4 = 'STRING_RESULT/B4.0/all_iterations'\n",
    "\n",
    "# Open all dataframes\n",
    "S1 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3644.csv')\n",
    "S2 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3441.csv')\n",
    "S3 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_280.csv')\n",
    "S4 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_5991.csv')\n",
    "S5 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_7917.csv')\n",
    "\n",
    "seeds_B3 = {\n",
    "    \"S1\": [S1],\n",
    "    \"S2\": [S2],\n",
    "    \"S3\": [S3],\n",
    "    \"S4\": [S4],\n",
    "    \"S5\": [S5]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:10:57.528328Z",
     "end_time": "2024-06-05T11:10:57.644239Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Evaluate missed batches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0     Missed batch\n0           0   3441 - I1 - B4\n1           1   280 - I1 - B36\n2           2  5991 - I1 - B25\n3           3  7917 - I1 - B10\n4           4  7917 - I1 - B26",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Missed batch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3441 - I1 - B4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>280 - I1 - B36</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5991 - I1 - B25</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7917 - I1 - B10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>7917 - I1 - B26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate missed batches\n",
    "B4_missed = pd.read_csv('STRING_RESULT/B4.0/T0_missed_batches.csv')\n",
    "B4_missed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:10:59.420888Z",
     "end_time": "2024-06-05T11:10:59.435445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "not evaluated                  501\ngeneral normative statement    216\nutilitarian                    195\negalitarian                    150\nprioritarian                    84\nsufficientarian                 33\ncooperation                      7\nurgency                          5\nlibertarian                      1\nName: PRINCIPLE_y, dtype: int64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3['PRINCIPLE_y'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:12:33.800482Z",
     "end_time": "2024-06-05T11:12:33.853743Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "not evaluated                            448\nurgency                                  185\ncooperation                              137\nUNFCCC agreements and principles          87\nother                                     77\nmitigation                                77\nfinancial mechanisms                      67\nnew UNFCCC policy                         50\nadaptation                                42\nadaptation and mitigation                 34\ntechnological resources                    4\nsupport                                    3\nfinancial and technological resources      1\nName: TOPIC_y, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1['TOPIC_y'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:11:05.715918Z",
     "end_time": "2024-06-05T11:11:05.735432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "not evaluated                            463\nnot indicated                            327\nresponsibility                           223\nfinancial resources                       81\nsupport                                   62\ntechnological resources                   28\nfinancial and technological resources     28\nName: UNIT_y, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1['UNIT_y'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:11:24.751811Z",
     "end_time": "2024-06-05T11:11:24.783006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "not evaluated                   460\nnot indicated                   420\nequality                        101\npriority to worst off            92\nneeds based                      53\nproportional to commitment       41\nequity                           28\nproportional to contribution     17\nName: SHAPE_y, dtype: int64"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1['SHAPE_y'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-05T11:11:47.050940Z",
     "end_time": "2024-06-05T11:11:47.071570Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate missed batches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Evaluate metrics - S1\n",
    "Evaluation is performed with SKLEARN - presenting 5 classification reports\n",
    "\n",
    "Column x is the ground truth label - y is the predicted label\n",
    "Evaluate per seed all classification reports per category\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S5['PRINCIPLE_x'],S5['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T14:23:42.472128Z",
     "end_time": "2024-06-03T14:23:42.513231Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S1['TOPIC_x'],S1['TOPIC_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:34:47.223663Z",
     "end_time": "2024-06-03T13:34:47.277029Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S1['UNIT_x'],S1['UNIT_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:34:50.343485Z",
     "end_time": "2024-06-03T13:34:50.394682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S1['SHAPE_x'],S1['SHAPE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:34:52.801380Z",
     "end_time": "2024-06-03T13:34:52.847673Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This batch has something wrong with saving results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S5['PRINCIPLE_x'],S5['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:35:42.831334Z",
     "end_time": "2024-06-03T13:35:42.892105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metrics over 5 seeds are very similar.\n",
    "Macro avg: average of all classes (aka labels)\n",
    "Weighted avg: weighted average, taking class balances into account."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Confusion matrix\n",
    "Evaluate where misclassifications are found - Again for each seed. - account for wrong saves for seed 4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = ['egalitarian', 'general normative statement', 'libertarian','not evaluated',\n",
    "          'prioritarian', 'sufficientarian', 'utilitarian']\n",
    "# Number of plots\n",
    "num_plots = len(seeds_B3)\n",
    "# Create plot names\n",
    "plot_names = list(seeds_B3.keys())\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(20, 20))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "for i, name in enumerate(plot_names):\n",
    "    df = seeds_B3[name][0]  # Access the dataframe\n",
    "    cm = confusion_matrix(df['PRINCIPLE_x'], df['PRINCIPLE_y'])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=axes[i])\n",
    "    axes[i].set_title(name)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:27:51.517710Z",
     "end_time": "2024-06-03T13:27:53.525712Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Evaluate misclassifications of sentences\n",
    "Special interest in relevant sentences that are incorrectly classified. Evaluate if the same sentences are misclassified in each seed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Results B3.1.1 - zero shot with context\n",
    "Only seed S1-S3 available. Others are not saved correctly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#B1.0\n",
    "path_B311 = 'STRING_RESULT/B3.1.1/all_iterations'\n",
    "\n",
    "# Open all dataframes\n",
    "S1_311 = pd.read_csv(f'{path_B311}/all_iterations_string_T0_3644.csv')\n",
    "S2_311 = pd.read_csv(f'{path_B311}/all_iterations_string_T0_3441.csv')\n",
    "S3_311 = pd.read_csv(f'{path_B311}/all_iterations_string_T0_280.csv')\n",
    "\n",
    "seeds_B311 = {\n",
    "    \"S1\": [S1_311],\n",
    "    \"S2\": [S2_311],\n",
    "    \"S3\": [S3_311],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:40:20.666755Z",
     "end_time": "2024-06-03T13:40:20.747626Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Evaluate missed batches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate missed batches\n",
    "B311_missed = pd.read_csv('STRING_RESULT/B3.1.1/T0_missed_batches.csv')\n",
    "B311_missed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:40:27.201264Z",
     "end_time": "2024-06-03T13:40:27.237810Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "S1: 2 batches (40 sentences) missed\n",
    "S2: 2 batches (40 sentences) missed\n",
    "S3: 4 batches (80 sentences) missed\n",
    "S4: 1 batch (20 sentences) missed\n",
    "S5: 4 batches (80 sentences) missed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Evaluate metrics\n",
    "Evaluation is performed with SKLEARN - presenting 5 classification reports\n",
    "\n",
    "Column RELEVANCE_x is the ground truth label - RELEVANCE_y is the predicted label\n",
    "\n",
    "Save as dataframes - if neccessary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S1_311['PRINCIPLE_x'],S1_311['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:40:35.699069Z",
     "end_time": "2024-06-03T13:40:35.755340Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S2_311['PRINCIPLE_x'],S2_311['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:40:45.096564Z",
     "end_time": "2024-06-03T13:40:45.144655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(S3_311['PRINCIPLE_x'],S3_311['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-03T13:40:52.617487Z",
     "end_time": "2024-06-03T13:40:52.672799Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ook een fout in deze opslag, met > 100 egalitarian labels - wat niet kan kloppen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
