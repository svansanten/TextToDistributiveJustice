{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import difflib\n",
    "from collections import Counter\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:03:37.979840Z",
     "end_time": "2024-06-07T22:03:38.483322Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Results B4.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Import Results\n",
    "Results created under the same fingerprint are saved in a CSV file for each seed. All results are combined into one dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#B1.0\n",
    "path_B4 = 'STRING_RESULT_TRAIN/B4.0/all_iterations'\n",
    "\n",
    "# Open all dataframes\n",
    "S1 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3644.csv')\n",
    "S2 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3441.csv')\n",
    "S3 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_280.csv')\n",
    "S4 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_5991.csv')\n",
    "S5 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_7917.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:20:59.456420Z",
     "end_time": "2024-06-07T21:20:59.665363Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(5960, 12)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate if predictions are correctly saved\n",
    "# Combine all dataframes into one\n",
    "B4_full_OG = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full_OG.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:00.893832Z",
     "end_time": "2024-06-07T21:21:00.945732Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def filter_dataframe(df, principles=None, units=None, shapes=None, topics=None):\n",
    "    if principles:\n",
    "        df = df[df['PRINCIPLE_y'].isin(principles)]\n",
    "    if units:\n",
    "        df = df[df['UNIT_y'].isin(units)]\n",
    "    if shapes:\n",
    "        df = df[df['SHAPE_y'].isin(shapes)]\n",
    "    if topics:\n",
    "        df = df[df['TOPIC_y'].isin(topic)]\n",
    "    return df\n",
    "\n",
    "principle = ['egalitarian', 'general normative statement', 'not evaluated', 'libertarian', 'not evaluated','prioritarian', 'sufficientarian', 'utilitarian']\n",
    "unit = ['not indicated', 'not evaluated', 'responsibility','financial resources', 'technological resources', 'financial and technological resources', 'support', 'other']\n",
    "shape = ['not indicated', 'not evaluated', 'equity', 'equality','priority to worst off', 'needs based', 'proportional to contribution', 'proportional to commitment']\n",
    "topic = ['new UNFCCC policy', 'UNFCCC agreements and principles', 'urgency', 'cooperation', 'financial mechanisms', 'adaptation', 'mitigation', 'adaptation and mitigation', 'other']\n",
    "\n",
    "S1 = filter_dataframe(S1, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S2 = filter_dataframe(S2, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S3 = filter_dataframe(S3, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S4 = filter_dataframe(S4, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S5 = filter_dataframe(S5, principles=principle, units=unit, shapes=shape, topics=topic)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:10.708032Z",
     "end_time": "2024-06-07T21:21:10.819587Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________________________________\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(3708, 12)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all dataframes into one\n",
    "B4_full = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:12.107710Z",
     "end_time": "2024-06-07T21:21:12.166449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(3220, 12)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows to keep only those where the unique_id appears exactly 5 times\n",
    "filtered_B4 = B4_full.groupby('unique_id').filter(lambda x: len(x) == 5)\n",
    "filtered_B4.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:13.161908Z",
     "end_time": "2024-06-07T21:21:13.280697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# List of unique_id's that are annotated 5 times\n",
    "unique_ids = filtered_B4['unique_id'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:14.121883Z",
     "end_time": "2024-06-07T21:21:14.189621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Filter all original dataframes to only include sentences that are annotated 5x by other seeds\n",
    "FB1S1 = S1[S1['unique_id'].isin(unique_ids)]\n",
    "FB1S2 = S2[S2['unique_id'].isin(unique_ids)]\n",
    "FB1S3 = S3[S3['unique_id'].isin(unique_ids)]\n",
    "FB1S4 = S4[S4['unique_id'].isin(unique_ids)]\n",
    "FB1S5 = S5[S5['unique_id'].isin(unique_ids)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:14.989438Z",
     "end_time": "2024-06-07T21:21:15.050310Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for S1\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.224806  0.630435  0.331429   46.000000\n",
      "general normative statement   0.063953  0.392857  0.110000   28.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "not evaluated                 1.000000  0.090308  0.165657  454.000000\n",
      "prioritarian                  0.272727  0.368421  0.313433   57.000000\n",
      "sufficientarian               0.085714  0.375000  0.139535    8.000000\n",
      "utilitarian                   0.195767  0.740000  0.309623   50.000000\n",
      "accuracy                      0.220497  0.220497  0.220497    0.220497\n",
      "macro avg                     0.263281  0.371003  0.195668  644.000000\n",
      "weighted avg                  0.764210  0.220497  0.198753  644.000000\n",
      "\n",
      "\n",
      "Classification Report for S2\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.229508  0.608696  0.333333   46.000000\n",
      "general normative statement   0.065934  0.428571  0.114286   28.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "not evaluated                 1.000000  0.094714  0.173038  454.000000\n",
      "prioritarian                  0.280488  0.403509  0.330935   57.000000\n",
      "sufficientarian               0.147059  0.625000  0.238095    8.000000\n",
      "utilitarian                   0.188889  0.680000  0.295652   50.000000\n",
      "accuracy                      0.225155  0.225155  0.225155    0.225155\n",
      "macro avg                     0.273125  0.405784  0.212191  644.000000\n",
      "weighted avg                  0.765547  0.225155  0.205968  644.000000\n",
      "\n",
      "\n",
      "Classification Report for S3\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.220588  0.652174  0.329670   46.000000\n",
      "general normative statement   0.074286  0.464286  0.128079   28.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "not evaluated                 0.980769  0.112335  0.201581  454.000000\n",
      "prioritarian                  0.256757  0.333333  0.290076   57.000000\n",
      "sufficientarian               0.125000  0.500000  0.200000    8.000000\n",
      "utilitarian                   0.178161  0.620000  0.276786   50.000000\n",
      "accuracy                      0.229814  0.229814  0.229814    0.229814\n",
      "macro avg                     0.262223  0.383161  0.203742  644.000000\n",
      "weighted avg                  0.748508  0.229814  0.220873  644.000000\n",
      "\n",
      "\n",
      "Classification Report for S4\n",
      "                             precision    recall  f1-score    support\n",
      "egalitarian                   0.241935  0.652174  0.352941   46.00000\n",
      "general normative statement   0.061350  0.357143  0.104712   28.00000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.00000\n",
      "not evaluated                 1.000000  0.096916  0.176707  454.00000\n",
      "prioritarian                  0.265823  0.368421  0.308824   57.00000\n",
      "sufficientarian               0.117647  0.500000  0.190476    8.00000\n",
      "utilitarian                   0.170854  0.680000  0.273092   50.00000\n",
      "accuracy                      0.222050  0.222050  0.222050    0.22205\n",
      "macro avg                     0.265373  0.379236  0.200965  644.00000\n",
      "weighted avg                  0.763172  0.222050  0.205238  644.00000\n",
      "\n",
      "\n",
      "Classification Report for S5\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.226277  0.673913  0.338798   46.000000\n",
      "general normative statement   0.069620  0.392857  0.118280   28.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "not evaluated                 1.000000  0.099119  0.180361  454.000000\n",
      "prioritarian                  0.263158  0.350877  0.300752   57.000000\n",
      "sufficientarian               0.085714  0.375000  0.139535    8.000000\n",
      "utilitarian                   0.187500  0.720000  0.297521   50.000000\n",
      "accuracy                      0.226708  0.226708  0.226708    0.226708\n",
      "macro avg                     0.261753  0.373109  0.196464  644.000000\n",
      "weighted avg                  0.763073  0.226708  0.207943  644.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of individual seeds for the same sentences\n",
    "# Function to generate classification report for each dataframe\n",
    "def generate_classification_report(df, true_label_col, pred_label_col):\n",
    "    return classification_report(df[true_label_col], df[pred_label_col], output_dict=True)\n",
    "\n",
    "# Generate classification reports\n",
    "report_S1 = generate_classification_report(FB1S1, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S2 = generate_classification_report(FB1S2, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S3 = generate_classification_report(FB1S3, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S4 = generate_classification_report(FB1S4, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S5 = generate_classification_report(FB1S5, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "\n",
    "# Function to print the classification reports for easy comparison\n",
    "def print_classification_report(report, title):\n",
    "    print(f\"Classification Report for {title}\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the classification reports\n",
    "print_classification_report(report_S1, \"S1\")\n",
    "print_classification_report(report_S2, \"S2\")\n",
    "print_classification_report(report_S3, \"S3\")\n",
    "print_classification_report(report_S4, \"S4\")\n",
    "print_classification_report(report_S5, \"S5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:15.614947Z",
     "end_time": "2024-06-07T21:21:15.744328Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate consistency of predictions over the 5 different instances - see which sentences are not consistantly predicted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(1895, 12)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def columns_not_uniform(group, columns):\n",
    "    for col in columns:\n",
    "        if group[col].nunique() != 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Columns to check for uniformity\n",
    "columns_to_check = ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y','TOPIC_y']\n",
    "\n",
    "# Group by 'unique_id' and filter groups\n",
    "B4_consistency = filtered_B4.groupby('unique_id').filter(lambda x: columns_not_uniform(x, columns_to_check))\n",
    "\n",
    "B4_consistency.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:19.961453Z",
     "end_time": "2024-06-07T21:21:20.359099Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "In combined dataframe, groupyby unique ID and take the majority label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     unique_id                                               text  \\\n0            3   Mr. President:  A fair and effective framewor...   \n1            4   In this regard, Japan firmly supports the est...   \n2            5  Such a framework must be based on “nationally ...   \n3           21   We will strategically promote mitigation meas...   \n4           24   Using that opportunity, we will launch a new ...   \n..         ...                                                ...   \n639       1201                    And COP28 is our moment to act.   \n640       1202   The first global stocktake of the Paris Agree...   \n641       1204                We must deliver on our commitments.   \n642       1205   We need a course correction, and working toge...   \n643       1206  Together we can: • Collaborate and partner to ...   \n\n                     PRINCIPLE_x                           TOPIC_x  \\\n0                    utilitarian                 new UNFCCC policy   \n1                  not evaluated                     not evaluated   \n2                    egalitarian                 new UNFCCC policy   \n3                  not evaluated                     not evaluated   \n4                  not evaluated                     not evaluated   \n..                           ...                               ...   \n639                not evaluated                     not evaluated   \n640                not evaluated                     not evaluated   \n641  general normative statement  UNFCCC agreements and principles   \n642                  utilitarian                       cooperation   \n643                not evaluated                     not evaluated   \n\n             UNIT_x                     SHAPE_x  \\\n0    responsibility                    equality   \n1     not evaluated               not evaluated   \n2    responsibility                      equity   \n3     not evaluated               not evaluated   \n4     not evaluated               not evaluated   \n..              ...                         ...   \n639   not evaluated               not evaluated   \n640   not evaluated               not evaluated   \n641   not indicated  proportional to commitment   \n642   not indicated               not indicated   \n643   not evaluated               not evaluated   \n\n                                             llm_query  \\\n0    3  Mr. President:  A fair and effective framew...   \n1    4  In this regard, Japan firmly supports the e...   \n2    5 Such a framework must be based on “nationall...   \n3    21  We will strategically promote mitigation m...   \n4    24  Using that opportunity, we will launch a n...   \n..                                                 ...   \n639             1201 And COP28 is our moment to act.\\n   \n640  1202  The first global stocktake of the Paris ...   \n641         1204 We must deliver on our commitments.\\n   \n642  1205  We need a course correction, and working...   \n643  1206 Together we can: • Collaborate and partne...   \n\n                     PRINCIPLE_y                           TOPIC_y  \\\n0                    egalitarian  UNFCCC agreements and principles   \n1    general normative statement                 new UNFCCC policy   \n2    general normative statement                 new UNFCCC policy   \n3    general normative statement                        mitigation   \n4    general normative statement                 new UNFCCC policy   \n..                           ...                               ...   \n639  general normative statement                           urgency   \n640  general normative statement  UNFCCC agreements and principles   \n641  general normative statement  UNFCCC agreements and principles   \n642                  utilitarian                       cooperation   \n643                  utilitarian                       cooperation   \n\n                                    UNIT_y                     SHAPE_y  \\\n0                           responsibility                    equality   \n1                            not indicated               not indicated   \n2                            not indicated               not indicated   \n3                            not indicated               not indicated   \n4                            not indicated               not indicated   \n..                                     ...                         ...   \n639                          not indicated               not indicated   \n640                          not indicated               not indicated   \n641                         responsibility  proportional to commitment   \n642                          not indicated               not indicated   \n643  financial and technological resources               not indicated   \n\n     iteration  \n0            1  \n1            1  \n2            1  \n3            1  \n4            1  \n..         ...  \n639          1  \n640          1  \n641          1  \n642          1  \n643          1  \n\n[644 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>text</th>\n      <th>PRINCIPLE_x</th>\n      <th>TOPIC_x</th>\n      <th>UNIT_x</th>\n      <th>SHAPE_x</th>\n      <th>llm_query</th>\n      <th>PRINCIPLE_y</th>\n      <th>TOPIC_y</th>\n      <th>UNIT_y</th>\n      <th>SHAPE_y</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Mr. President:  A fair and effective framewor...</td>\n      <td>utilitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>3  Mr. President:  A fair and effective framew...</td>\n      <td>egalitarian</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>In this regard, Japan firmly supports the est...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>4  In this regard, Japan firmly supports the e...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>Such a framework must be based on “nationally ...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equity</td>\n      <td>5 Such a framework must be based on “nationall...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21</td>\n      <td>We will strategically promote mitigation meas...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>21  We will strategically promote mitigation m...</td>\n      <td>general normative statement</td>\n      <td>mitigation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24</td>\n      <td>Using that opportunity, we will launch a new ...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>24  Using that opportunity, we will launch a n...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>639</th>\n      <td>1201</td>\n      <td>And COP28 is our moment to act.</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>1201 And COP28 is our moment to act.\\n</td>\n      <td>general normative statement</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>640</th>\n      <td>1202</td>\n      <td>The first global stocktake of the Paris Agree...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>1202  The first global stocktake of the Paris ...</td>\n      <td>general normative statement</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>1204</td>\n      <td>We must deliver on our commitments.</td>\n      <td>general normative statement</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>not indicated</td>\n      <td>proportional to commitment</td>\n      <td>1204 We must deliver on our commitments.\\n</td>\n      <td>general normative statement</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>responsibility</td>\n      <td>proportional to commitment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>642</th>\n      <td>1205</td>\n      <td>We need a course correction, and working toge...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1205  We need a course correction, and working...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>1206</td>\n      <td>Together we can: • Collaborate and partner to ...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>1206 Together we can: • Collaborate and partne...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>financial and technological resources</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>644 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_frequent_except_principle(x):\n",
    "    if x.name in ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y', 'TOPIC_y']:\n",
    "        return Counter(x).most_common(1)[0][0]\n",
    "    return x.iloc[0]  # Keep the first value for other columns\n",
    "\n",
    "# Dictionary to specify aggregation functions for all columns\n",
    "agg_dict_all = {col: most_frequent_except_principle for col in filtered_B4.columns if col != 'unique_id'}\n",
    "\n",
    "# Group by 'unique_id' and apply the aggregation functions\n",
    "filtered_B4_grouped = filtered_B4.groupby('unique_id').agg(agg_dict_all).reset_index()\n",
    "\n",
    "filtered_B4_grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:28.531001Z",
     "end_time": "2024-06-07T21:21:28.988840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                egalitarian       0.23      0.65      0.34        46\n",
      "general normative statement       0.07      0.43      0.12        28\n",
      "                libertarian       0.00      0.00      0.00         1\n",
      "              not evaluated       1.00      0.09      0.17       454\n",
      "               prioritarian       0.28      0.37      0.32        57\n",
      "            sufficientarian       0.11      0.50      0.19         8\n",
      "                utilitarian       0.19      0.72      0.30        50\n",
      "\n",
      "                   accuracy                           0.22       644\n",
      "                  macro avg       0.27      0.39      0.20       644\n",
      "               weighted avg       0.76      0.22      0.20       644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - principle\n",
    "print(classification_report(filtered_B4_grouped['PRINCIPLE_x'],filtered_B4_grouped['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:29.604919Z",
     "end_time": "2024-06-07T21:21:29.770375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "UNFCCC agreements and principles       0.15      0.44      0.23        25\n",
      "                      adaptation       0.03      1.00      0.06         1\n",
      "       adaptation and mitigation       0.13      0.44      0.21         9\n",
      "                     cooperation       0.13      0.71      0.22        21\n",
      "            financial mechanisms       0.33      0.95      0.49        20\n",
      "                      mitigation       0.06      0.67      0.11         6\n",
      "               new UNFCCC policy       0.21      0.29      0.24        35\n",
      "                   not evaluated       0.00      0.00      0.00       454\n",
      "                           other       0.18      0.24      0.20        42\n",
      "                         urgency       0.14      0.74      0.24        31\n",
      "\n",
      "                        accuracy                           0.15       644\n",
      "                       macro avg       0.14      0.55      0.20       644\n",
      "                    weighted avg       0.05      0.15      0.07       644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['TOPIC_x'],filtered_B4_grouped['TOPIC_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:21:49.801749Z",
     "end_time": "2024-06-07T21:21:49.883475Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "financial and technological resources       0.30      0.88      0.45         8\n",
      "                  financial resources       0.37      0.96      0.53        27\n",
      "                        not evaluated       1.00      0.03      0.06       454\n",
      "                        not indicated       0.16      0.42      0.23        92\n",
      "                                other       0.00      0.00      0.00         2\n",
      "                       responsibility       0.17      0.80      0.28        45\n",
      "                              support       0.19      0.67      0.29        15\n",
      "              technological resources       0.06      1.00      0.11         1\n",
      "\n",
      "                             accuracy                           0.21       644\n",
      "                            macro avg       0.28      0.59      0.24       644\n",
      "                         weighted avg       0.76      0.21      0.13       644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['UNIT_x'],filtered_B4_grouped['UNIT_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:22:06.250573Z",
     "end_time": "2024-06-07T21:22:06.322473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                    equality       0.03      0.30      0.06        10\n",
      "                      equity       0.24      0.43      0.31        14\n",
      "                 needs based       0.05      0.75      0.10         4\n",
      "               not evaluated       1.00      0.03      0.06       456\n",
      "               not indicated       0.18      0.56      0.27       113\n",
      "       priority to worst off       0.15      0.39      0.21        28\n",
      "  proportional to commitment       0.34      0.65      0.45        17\n",
      "proportional to contribution       0.17      0.50      0.25         2\n",
      "\n",
      "                    accuracy                           0.17       644\n",
      "                   macro avg       0.27      0.45      0.21       644\n",
      "                weighted avg       0.76      0.17      0.12       644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['SHAPE_x'],filtered_B4_grouped['SHAPE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:22:23.640512Z",
     "end_time": "2024-06-07T21:22:23.729254Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TEST SET 4.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#B1.0\n",
    "path_B4 = 'STRING_RESULT/B4.0/all_iterations'\n",
    "\n",
    "# Open all dataframes\n",
    "S1 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3644.csv')\n",
    "S2 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3441.csv')\n",
    "S3 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_280.csv')\n",
    "S4 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_5991.csv')\n",
    "S5 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_7917.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:22:34.155575Z",
     "end_time": "2024-06-07T21:22:34.277238Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(1615, 12)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate if predictions are correctly saved\n",
    "# Combine all dataframes into one\n",
    "B4_full_OG = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full_OG.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:22:35.958060Z",
     "end_time": "2024-06-07T21:22:35.994020Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def filter_dataframe(df, principles=None, units=None, shapes=None, topics=None):\n",
    "    if principles:\n",
    "        df = df[df['PRINCIPLE_y'].isin(principles)]\n",
    "    if units:\n",
    "        df = df[df['UNIT_y'].isin(units)]\n",
    "    if shapes:\n",
    "        df = df[df['SHAPE_y'].isin(shapes)]\n",
    "    if topics:\n",
    "        df = df[df['TOPIC_y'].isin(topic)]\n",
    "    return df\n",
    "\n",
    "principle = ['egalitarian', 'general normative statement', 'not evaluated', 'libertarian', 'not evaluated','prioritarian', 'sufficientarian', 'utilitarian']\n",
    "unit = ['not indicated', 'not evaluated', 'responsibility','financial resources', 'technological resources', 'financial and technological resources', 'support', 'other']\n",
    "shape = ['not indicated', 'not evaluated', 'equity', 'equality','priority to worst off', 'needs based', 'proportional to contribution', 'proportional to commitment']\n",
    "topic = ['new UNFCCC policy', 'UNFCCC agreements and principles', 'urgency', 'cooperation', 'financial mechanisms', 'adaptation', 'mitigation', 'adaptation and mitigation', 'other']\n",
    "\n",
    "S1 = filter_dataframe(S1, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S2 = filter_dataframe(S2, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S3 = filter_dataframe(S3, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S4 = filter_dataframe(S4, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S5 = filter_dataframe(S5, principles=principle, units=unit, shapes=shape, topics=topic)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:22:40.236932Z",
     "end_time": "2024-06-07T21:22:40.287124Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________________________________\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(911, 12)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all dataframes into one\n",
    "B4_full = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:02.483860Z",
     "end_time": "2024-06-07T21:23:02.529727Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(710, 12)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows to keep only those where the unique_id appears exactly 5 times\n",
    "filtered_B4 = B4_full.groupby('unique_id').filter(lambda x: len(x) == 5)\n",
    "filtered_B4.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:02.989511Z",
     "end_time": "2024-06-07T21:23:03.035756Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# List of unique_id's that are annotated 5 times\n",
    "unique_ids = filtered_B4['unique_id'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:04.536220Z",
     "end_time": "2024-06-07T21:23:04.599973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Filter all original dataframes to only include sentences that are annotated 5x by other seeds\n",
    "FB1S1 = S1[S1['unique_id'].isin(unique_ids)]\n",
    "FB1S2 = S2[S2['unique_id'].isin(unique_ids)]\n",
    "FB1S3 = S3[S3['unique_id'].isin(unique_ids)]\n",
    "FB1S4 = S4[S4['unique_id'].isin(unique_ids)]\n",
    "FB1S5 = S5[S5['unique_id'].isin(unique_ids)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:05.644697Z",
     "end_time": "2024-06-07T21:23:05.688654Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for S1\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.322581  0.666667  0.434783   15.000000\n",
      "general normative statement   0.065217  0.250000  0.103448   12.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    2.000000\n",
      "not evaluated                 1.000000  0.088235  0.162162  102.000000\n",
      "prioritarian                  0.272727  0.600000  0.375000    5.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000    1.000000\n",
      "utilitarian                   0.055556  0.400000  0.097561    5.000000\n",
      "accuracy                      0.190141  0.190141  0.190141    0.190141\n",
      "macro avg                     0.245154  0.286415  0.167565  142.000000\n",
      "weighted avg                  0.769456  0.190141  0.187792  142.000000\n",
      "\n",
      "\n",
      "Classification Report for S2\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.354839  0.733333  0.478261   15.000000\n",
      "general normative statement   0.052632  0.166667  0.080000   12.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    2.000000\n",
      "not evaluated                 1.000000  0.088235  0.162162  102.000000\n",
      "prioritarian                  0.300000  0.600000  0.400000    5.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000    1.000000\n",
      "utilitarian                   0.043478  0.400000  0.078431    5.000000\n",
      "accuracy                      0.190141  0.190141  0.190141    0.190141\n",
      "macro avg                     0.250136  0.284034  0.171265  142.000000\n",
      "weighted avg                  0.772335  0.190141  0.190610  142.000000\n",
      "\n",
      "\n",
      "Classification Report for S3\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.333333  0.733333  0.458333   15.000000\n",
      "general normative statement   0.108108  0.333333  0.163265   12.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    2.000000\n",
      "not evaluated                 1.000000  0.068627  0.128440  102.000000\n",
      "prioritarian                  0.272727  0.600000  0.375000    5.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000    1.000000\n",
      "utilitarian                   0.043478  0.400000  0.078431    5.000000\n",
      "accuracy                      0.190141  0.190141  0.190141    0.190141\n",
      "macro avg                     0.251092  0.305042  0.171924  142.000000\n",
      "weighted avg                  0.773791  0.190141  0.170438  142.000000\n",
      "\n",
      "\n",
      "Classification Report for S4\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.354839  0.733333  0.478261   15.000000\n",
      "general normative statement   0.031250  0.083333  0.045455   12.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    2.000000\n",
      "not evaluated                 1.000000  0.166667  0.285714  102.000000\n",
      "prioritarian                  0.272727  0.600000  0.375000    5.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000    1.000000\n",
      "utilitarian                   0.023256  0.200000  0.041667    5.000000\n",
      "accuracy                      0.232394  0.232394  0.232394    0.232394\n",
      "macro avg                     0.240296  0.254762  0.175157  142.000000\n",
      "weighted avg                  0.768856  0.232394  0.274264  142.000000\n",
      "\n",
      "\n",
      "Classification Report for S5\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.294118  0.666667  0.408163   15.000000\n",
      "general normative statement   0.093750  0.250000  0.136364   12.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    2.000000\n",
      "not evaluated                 1.000000  0.127451  0.226087  102.000000\n",
      "prioritarian                  0.272727  0.600000  0.375000    5.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000    1.000000\n",
      "utilitarian                   0.022727  0.200000  0.040816    5.000000\n",
      "accuracy                      0.211268  0.211268  0.211268    0.211268\n",
      "macro avg                     0.240475  0.263445  0.169490  142.000000\n",
      "weighted avg                  0.767704  0.211268  0.231681  142.000000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of individual seeds for the same sentences\n",
    "# Function to generate classification report for each dataframe\n",
    "def generate_classification_report(df, true_label_col, pred_label_col):\n",
    "    return classification_report(df[true_label_col], df[pred_label_col], output_dict=True)\n",
    "\n",
    "# Generate classification reports\n",
    "report_S1 = generate_classification_report(FB1S1, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S2 = generate_classification_report(FB1S2, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S3 = generate_classification_report(FB1S3, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S4 = generate_classification_report(FB1S4, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S5 = generate_classification_report(FB1S5, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "\n",
    "# Function to print the classification reports for easy comparison\n",
    "def print_classification_report(report, title):\n",
    "    print(f\"Classification Report for {title}\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the classification reports\n",
    "print_classification_report(report_S1, \"S1\")\n",
    "print_classification_report(report_S2, \"S2\")\n",
    "print_classification_report(report_S3, \"S3\")\n",
    "print_classification_report(report_S4, \"S4\")\n",
    "print_classification_report(report_S5, \"S5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:06.206188Z",
     "end_time": "2024-06-07T21:23:06.383445Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate consistency of predictions over the 5 different instances - see which sentences are not consistantly predicted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(430, 12)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def columns_not_uniform(group, columns):\n",
    "    for col in columns:\n",
    "        if group[col].nunique() != 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Columns to check for uniformity\n",
    "columns_to_check = ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y','TOPIC_y']\n",
    "\n",
    "# Group by 'unique_id' and filter groups\n",
    "B4_consistency = filtered_B4.groupby('unique_id').filter(lambda x: columns_not_uniform(x, columns_to_check))\n",
    "\n",
    "B4_consistency.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:08.244125Z",
     "end_time": "2024-06-07T21:23:08.406811Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "In combined dataframe, groupyby unique ID and take the majority label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "     unique_id                                               text  \\\n0            2    Of course, scientists dont know that clima...   \n1            3    It is for this reason that President Obama ...   \n2           12    The U.S. also continues to play an importan...   \n3           13  •  Simultaneously, we are fully engaged in cra...   \n4           14  We have advocated a structure for the new agre...   \n..         ...                                                ...   \n137        318   Especially with Africa , which harnesses 40% ...   \n138        325   Mr. President, Your Excellencies,  Ladies and...   \n139        326   The most important result of COP28 that I wou...   \n140        327   Trust that “WE” , governments together with o...   \n141        329  But for that, we need….to scale up the solutio...   \n\n                     PRINCIPLE_x            TOPIC_x          UNIT_x  \\\n0                  not evaluated      not evaluated   not evaluated   \n1                  not evaluated      not evaluated   not evaluated   \n2                  not evaluated      not evaluated   not evaluated   \n3                  not evaluated      not evaluated   not evaluated   \n4                    egalitarian  new UNFCCC policy  responsibility   \n..                           ...                ...             ...   \n137                not evaluated      not evaluated   not evaluated   \n138                  egalitarian        cooperation   not indicated   \n139                not evaluated      not evaluated   not evaluated   \n140                not evaluated      not evaluated   not evaluated   \n141  general normative statement            urgency   not indicated   \n\n           SHAPE_x                                          llm_query  \\\n0    not evaluated  2   Of course, scientists dont know that cli...   \n1    not evaluated  3   It is for this reason that President Obam...   \n2    not evaluated  12   The U.S. also continues to play an impor...   \n3    not evaluated  13 •  Simultaneously, we are fully engaged in ...   \n4         equality  14 We have advocated a structure for the new a...   \n..             ...                                                ...   \n137  not evaluated  318  Especially with Africa , which harnesses ...   \n138  not indicated  325  Mr. President, Your Excellencies,  Ladies...   \n139  not evaluated  326  The most important result of COP28 that I...   \n140  not evaluated  327  Trust that “WE” , governments together wi...   \n141  not indicated  329 But for that, we need….to scale up the sol...   \n\n                     PRINCIPLE_y                           TOPIC_y  \\\n0                    utilitarian                           urgency   \n1                    utilitarian                       cooperation   \n2                    egalitarian              financial mechanisms   \n3    general normative statement                 new UNFCCC policy   \n4                    egalitarian                 new UNFCCC policy   \n..                           ...                               ...   \n137                  utilitarian                       cooperation   \n138  general normative statement                       cooperation   \n139  general normative statement                 new UNFCCC policy   \n140                  egalitarian  UNFCCC agreements and principles   \n141  general normative statement                           urgency   \n\n                      UNIT_y                     SHAPE_y  iteration  \n0              not indicated               not indicated          1  \n1             responsibility               not indicated          1  \n2        financial resources  proportional to commitment          1  \n3              not indicated               not indicated          1  \n4              not indicated                    equality          1  \n..                       ...                         ...        ...  \n137  technological resources               not indicated          1  \n138            not indicated               not indicated          1  \n139            not indicated               not indicated          1  \n140           responsibility                    equality          1  \n141            not indicated               not indicated          1  \n\n[142 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>text</th>\n      <th>PRINCIPLE_x</th>\n      <th>TOPIC_x</th>\n      <th>UNIT_x</th>\n      <th>SHAPE_x</th>\n      <th>llm_query</th>\n      <th>PRINCIPLE_y</th>\n      <th>TOPIC_y</th>\n      <th>UNIT_y</th>\n      <th>SHAPE_y</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>  Of course, scientists dont know that clima...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>2   Of course, scientists dont know that cli...</td>\n      <td>utilitarian</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>  It is for this reason that President Obama ...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>3   It is for this reason that President Obam...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>  The U.S. also continues to play an importan...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>12   The U.S. also continues to play an impor...</td>\n      <td>egalitarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>proportional to commitment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13</td>\n      <td>•  Simultaneously, we are fully engaged in cra...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>13 •  Simultaneously, we are fully engaged in ...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14</td>\n      <td>We have advocated a structure for the new agre...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>14 We have advocated a structure for the new a...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>318</td>\n      <td>Especially with Africa , which harnesses 40% ...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>318  Especially with Africa , which harnesses ...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>technological resources</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>325</td>\n      <td>Mr. President, Your Excellencies,  Ladies and...</td>\n      <td>egalitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>325  Mr. President, Your Excellencies,  Ladies...</td>\n      <td>general normative statement</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>326</td>\n      <td>The most important result of COP28 that I wou...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>326  The most important result of COP28 that I...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>327</td>\n      <td>Trust that “WE” , governments together with o...</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>327  Trust that “WE” , governments together wi...</td>\n      <td>egalitarian</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>141</th>\n      <td>329</td>\n      <td>But for that, we need….to scale up the solutio...</td>\n      <td>general normative statement</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>329 But for that, we need….to scale up the sol...</td>\n      <td>general normative statement</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>142 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_frequent_except_principle(x):\n",
    "    if x.name in ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y', 'TOPIC_y']:\n",
    "        return Counter(x).most_common(1)[0][0]\n",
    "    return x.iloc[0]  # Keep the first value for other columns\n",
    "\n",
    "# Dictionary to specify aggregation functions for all columns\n",
    "agg_dict_all = {col: most_frequent_except_principle for col in filtered_B4.columns if col != 'unique_id'}\n",
    "\n",
    "# Group by 'unique_id' and apply the aggregation functions\n",
    "filtered_B4_grouped = filtered_B4.groupby('unique_id').agg(agg_dict_all).reset_index()\n",
    "\n",
    "filtered_B4_grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:21.721688Z",
     "end_time": "2024-06-07T21:23:21.916509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                egalitarian       0.34      0.73      0.47        15\n",
      "general normative statement       0.09      0.25      0.13        12\n",
      "                libertarian       0.00      0.00      0.00         2\n",
      "              not evaluated       1.00      0.14      0.24       102\n",
      "               prioritarian       0.27      0.60      0.37         5\n",
      "            sufficientarian       0.00      0.00      0.00         1\n",
      "                utilitarian       0.05      0.40      0.09         5\n",
      "\n",
      "                   accuracy                           0.23       142\n",
      "                  macro avg       0.25      0.30      0.19       142\n",
      "               weighted avg       0.77      0.23      0.25       142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - principle\n",
    "print(classification_report(filtered_B4_grouped['PRINCIPLE_x'],filtered_B4_grouped['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:23.696941Z",
     "end_time": "2024-06-07T21:23:23.757997Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "UNFCCC agreements and principles       0.15      0.44      0.23        25\n",
      "                      adaptation       0.03      1.00      0.06         1\n",
      "       adaptation and mitigation       0.13      0.44      0.21         9\n",
      "                     cooperation       0.13      0.71      0.22        21\n",
      "            financial mechanisms       0.33      0.95      0.49        20\n",
      "                      mitigation       0.06      0.67      0.11         6\n",
      "               new UNFCCC policy       0.21      0.29      0.24        35\n",
      "                   not evaluated       0.00      0.00      0.00       454\n",
      "                           other       0.18      0.24      0.20        42\n",
      "                         urgency       0.14      0.74      0.24        31\n",
      "\n",
      "                        accuracy                           0.15       644\n",
      "                       macro avg       0.14      0.55      0.20       644\n",
      "                    weighted avg       0.05      0.15      0.07       644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['TOPIC_x'],filtered_B4_grouped['TOPIC_y']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       precision    recall  f1-score   support\n",
      "\n",
      "financial and technological resources       0.50      0.50      0.50         2\n",
      "                  financial resources       0.41      1.00      0.58         9\n",
      "                        not evaluated       0.00      0.00      0.00       102\n",
      "                        not indicated       0.10      0.46      0.16        13\n",
      "                                other       0.00      0.00      0.00         3\n",
      "                       responsibility       0.18      0.73      0.29        11\n",
      "                              support       0.20      1.00      0.33         1\n",
      "              technological resources       0.12      1.00      0.22         1\n",
      "\n",
      "                             accuracy                           0.18       142\n",
      "                            macro avg       0.19      0.59      0.26       142\n",
      "                         weighted avg       0.06      0.18      0.09       142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['UNIT_x'],filtered_B4_grouped['UNIT_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:33.946981Z",
     "end_time": "2024-06-07T21:23:34.009441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                    equality       0.19      0.83      0.30         6\n",
      "                      equity       0.50      1.00      0.67         3\n",
      "                 needs based       0.22      0.67      0.33         3\n",
      "               not evaluated       0.00      0.00      0.00       102\n",
      "               not indicated       0.11      0.43      0.18        21\n",
      "       priority to worst off       0.27      0.75      0.40         4\n",
      "  proportional to commitment       0.00      0.00      0.00         1\n",
      "proportional to contribution       0.25      0.50      0.33         2\n",
      "\n",
      "                    accuracy                           0.16       142\n",
      "                   macro avg       0.19      0.52      0.28       142\n",
      "                weighted avg       0.05      0.16      0.08       142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['SHAPE_x'],filtered_B4_grouped['SHAPE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:23:40.908184Z",
     "end_time": "2024-06-07T21:23:40.973976Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# B4.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#B1.0\n",
    "path_B4 = 'STRING_RESULT_TRAIN/B4.1/all_iterations'\n",
    "\n",
    "# Open all dataframes\n",
    "S1 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3644.csv')\n",
    "S2 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3441.csv')\n",
    "S3 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_280.csv')\n",
    "S4 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_5991.csv')\n",
    "S5 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_7917.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:03:56.537276Z",
     "end_time": "2024-06-07T22:03:56.592397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(218, 12)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:03:57.069871Z",
     "end_time": "2024-06-07T22:03:57.116384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(1070, 12)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate if predictions are correctly saved\n",
    "# Combine all dataframes into one\n",
    "B4_full_OG = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full_OG.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:03:58.610448Z",
     "end_time": "2024-06-07T22:03:58.681084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def filter_dataframe(df, principles=None, units=None, shapes=None, topics=None):\n",
    "    if principles:\n",
    "        df = df[df['PRINCIPLE_y'].isin(principles)]\n",
    "    if units:\n",
    "        df = df[df['UNIT_y'].isin(units)]\n",
    "    if shapes:\n",
    "        df = df[df['SHAPE_y'].isin(shapes)]\n",
    "    if topics:\n",
    "        df = df[df['TOPIC_y'].isin(topic)]\n",
    "    return df\n",
    "\n",
    "principle = ['egalitarian', 'general normative statement', 'libertarian', 'not evaluated','prioritarian', 'sufficientarian', 'utilitarian']\n",
    "unit = ['not indicated', 'responsibility','financial resources', 'technological resources', 'financial and technological resources', 'support', 'other']\n",
    "shape = ['not indicated', 'equity', 'equality','priority to worst off', 'needs based', 'proportional to contribution', 'proportional to commitment']\n",
    "topic = ['new UNFCCC policy', 'UNFCCC agreements and principles', 'urgency', 'cooperation', 'financial mechanisms', 'adaptation', 'mitigation', 'adaptation and mitigation', 'other']\n",
    "\n",
    "S1 = filter_dataframe(S1, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S2 = filter_dataframe(S2, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S3 = filter_dataframe(S3, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S4 = filter_dataframe(S4, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S5 = filter_dataframe(S5, principles=principle, units=unit, shapes=shape, topics=topic)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:03:59.386755Z",
     "end_time": "2024-06-07T22:03:59.455422Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________________________________\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(1057, 12)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all dataframes into one\n",
    "B4_full = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:00.612904Z",
     "end_time": "2024-06-07T22:04:00.653853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(970, 12)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows to keep only those where the unique_id appears exactly 5 times\n",
    "filtered_B4 = B4_full.groupby('unique_id').filter(lambda x: len(x) == 5)\n",
    "filtered_B4.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:01.138676Z",
     "end_time": "2024-06-07T22:04:01.166534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# List of unique_id's that are annotated 5 times\n",
    "unique_ids = filtered_B4['unique_id'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:01.645291Z",
     "end_time": "2024-06-07T22:04:01.693995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Filter all original dataframes to only include sentences that are annotated 5x by other seeds\n",
    "FB1S1 = S1[S1['unique_id'].isin(unique_ids)]\n",
    "FB1S2 = S2[S2['unique_id'].isin(unique_ids)]\n",
    "FB1S3 = S3[S3['unique_id'].isin(unique_ids)]\n",
    "FB1S4 = S4[S4['unique_id'].isin(unique_ids)]\n",
    "FB1S5 = S5[S5['unique_id'].isin(unique_ids)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:02.263825Z",
     "end_time": "2024-06-07T22:04:02.354859Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for S1\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.543860  0.645833  0.590476   48.000000\n",
      "general normative statement   0.400000  0.258065  0.313725   31.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "prioritarian                  0.823529  0.500000  0.622222   56.000000\n",
      "sufficientarian               0.294118  0.714286  0.416667    7.000000\n",
      "utilitarian                   0.538462  0.686275  0.603448   51.000000\n",
      "accuracy                      0.551546  0.551546  0.551546    0.551546\n",
      "macro avg                     0.433328  0.467410  0.424423  194.000000\n",
      "weighted avg                  0.588367  0.551546  0.549512  194.000000\n",
      "\n",
      "\n",
      "Classification Report for S2\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.555556  0.625000  0.588235   48.000000\n",
      "general normative statement   0.333333  0.193548  0.244898   31.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "prioritarian                  0.842105  0.571429  0.680851   56.000000\n",
      "sufficientarian               0.277778  0.714286  0.400000    7.000000\n",
      "utilitarian                   0.538462  0.686275  0.603448   51.000000\n",
      "accuracy                      0.556701  0.556701  0.556701    0.556701\n",
      "macro avg                     0.424539  0.465090  0.419572  194.000000\n",
      "weighted avg                  0.585381  0.556701  0.554282  194.000000\n",
      "\n",
      "\n",
      "Classification Report for S3\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.571429  0.583333  0.577320   48.000000\n",
      "general normative statement   0.440000  0.354839  0.392857   31.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "prioritarian                  0.815789  0.553571  0.659574   56.000000\n",
      "sufficientarian               0.277778  0.714286  0.400000    7.000000\n",
      "utilitarian                   0.548387  0.666667  0.601770   51.000000\n",
      "accuracy                      0.561856  0.561856  0.561856    0.561856\n",
      "macro avg                     0.442230  0.478783  0.438587  194.000000\n",
      "weighted avg                  0.601366  0.561856  0.568641  194.000000\n",
      "\n",
      "\n",
      "Classification Report for S4\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.525424  0.645833  0.579439   48.000000\n",
      "general normative statement   0.352941  0.193548  0.250000   31.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "prioritarian                  0.828571  0.517857  0.637363   56.000000\n",
      "sufficientarian               0.312500  0.714286  0.434783    7.000000\n",
      "utilitarian                   0.530303  0.686275  0.598291   51.000000\n",
      "accuracy                      0.546392  0.546392  0.546392    0.546392\n",
      "macro avg                     0.424957  0.459633  0.416646  194.000000\n",
      "weighted avg                  0.576260  0.546392  0.540266  194.000000\n",
      "\n",
      "\n",
      "Classification Report for S5\n",
      "                             precision    recall  f1-score     support\n",
      "egalitarian                   0.538462  0.583333  0.560000   48.000000\n",
      "general normative statement   0.400000  0.258065  0.313725   31.000000\n",
      "libertarian                   0.000000  0.000000  0.000000    1.000000\n",
      "prioritarian                  0.760000  0.339286  0.469136   56.000000\n",
      "sufficientarian               0.173913  0.571429  0.266667    7.000000\n",
      "utilitarian                   0.541667  0.764706  0.634146   51.000000\n",
      "accuracy                      0.505155  0.505155  0.505155    0.505155\n",
      "macro avg                     0.402340  0.419470  0.373946  194.000000\n",
      "weighted avg                  0.565199  0.505155  0.500439  194.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of individual seeds for the same sentences\n",
    "# Function to generate classification report for each dataframe\n",
    "def generate_classification_report(df, true_label_col, pred_label_col):\n",
    "    return classification_report(df[true_label_col], df[pred_label_col], output_dict=True)\n",
    "\n",
    "# Generate classification reports\n",
    "report_S1 = generate_classification_report(FB1S1, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S2 = generate_classification_report(FB1S2, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S3 = generate_classification_report(FB1S3, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S4 = generate_classification_report(FB1S4, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S5 = generate_classification_report(FB1S5, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "\n",
    "# Function to print the classification reports for easy comparison\n",
    "def print_classification_report(report, title):\n",
    "    print(f\"Classification Report for {title}\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the classification reports\n",
    "print_classification_report(report_S1, \"S1\")\n",
    "print_classification_report(report_S2, \"S2\")\n",
    "print_classification_report(report_S3, \"S3\")\n",
    "print_classification_report(report_S4, \"S4\")\n",
    "print_classification_report(report_S5, \"S5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:03.030394Z",
     "end_time": "2024-06-07T22:04:03.116496Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate consistency of predictions over the 5 different instances - see which sentences are not consistantly predicted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(430, 12)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def columns_not_uniform(group, columns):\n",
    "    for col in columns:\n",
    "        if group[col].nunique() != 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Columns to check for uniformity\n",
    "columns_to_check = ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y','TOPIC_y']\n",
    "\n",
    "# Group by 'unique_id' and filter groups\n",
    "B4_consistency = filtered_B4.groupby('unique_id').filter(lambda x: columns_not_uniform(x, columns_to_check))\n",
    "\n",
    "B4_consistency.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:04.682089Z",
     "end_time": "2024-06-07T22:04:04.844425Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "In combined dataframe, groupyby unique ID and take the majority label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "     unique_id                                               text  \\\n0            3   Mr. President:  A fair and effective framewor...   \n1            5  Such a framework must be based on “nationally ...   \n2           44  It should not only enable us to discuss global...   \n3           53  Global warming is a catastrophic problem that ...   \n4           54  Therefore, the multilateralism approach remain...   \n..         ...                                                ...   \n189       1172   As we work to catch up on lost time and progr...   \n190       1173   Conflict -ridden communities, refugees, and d...   \n191       1174  Nor can we stand by , as the massive destructi...   \n192       1198   We recognise that we must deliver on our coll...   \n193       1205   We need a course correction, and working toge...   \n\n                     PRINCIPLE_x               TOPIC_x               UNIT_x  \\\n0                    utilitarian     new UNFCCC policy       responsibility   \n1                    egalitarian     new UNFCCC policy       responsibility   \n2                    utilitarian     new UNFCCC policy        not indicated   \n3                    utilitarian               urgency        not indicated   \n4    general normative statement     new UNFCCC policy        not indicated   \n..                           ...                   ...                  ...   \n189                 prioritarian               urgency        not indicated   \n190                 prioritarian     new UNFCCC policy        not indicated   \n191                  utilitarian                 other        not indicated   \n192                 prioritarian  financial mechanisms  financial resources   \n193                  utilitarian           cooperation        not indicated   \n\n                        SHAPE_x  \\\n0                      equality   \n1                        equity   \n2                 not indicated   \n3                 not indicated   \n4                 not indicated   \n..                          ...   \n189               not indicated   \n190               not indicated   \n191               not indicated   \n192  proportional to commitment   \n193               not indicated   \n\n                                             llm_query  \\\n0    3  Mr. President:  A fair and effective framew...   \n1    5 Such a framework must be based on “nationall...   \n2    44 It should not only enable us to discuss glo...   \n3    53 Global warming is a catastrophic problem th...   \n4    54 Therefore, the multilateralism approach rem...   \n..                                                 ...   \n189  1172  As we work to catch up on lost time and ...   \n190  1173  Conflict -ridden communities, refugees, ...   \n191  1174 Nor can we stand by , as the massive dest...   \n192  1198  We recognise that we must deliver on our...   \n193  1205  We need a course correction, and working...   \n\n                     PRINCIPLE_y               TOPIC_y               UNIT_y  \\\n0                    egalitarian           cooperation       responsibility   \n1    general normative statement     new UNFCCC policy        not indicated   \n2                    utilitarian               urgency        not indicated   \n3                    utilitarian               urgency        not indicated   \n4                    utilitarian           cooperation        not indicated   \n..                           ...                   ...                  ...   \n189                 prioritarian           cooperation        not indicated   \n190                 prioritarian           cooperation        not indicated   \n191                  utilitarian           cooperation        not indicated   \n192              sufficientarian  financial mechanisms  financial resources   \n193                  utilitarian           cooperation        not indicated   \n\n                        SHAPE_y  iteration  \n0                      equality          1  \n1                 not indicated          1  \n2                 not indicated          1  \n3                 not indicated          1  \n4                 not indicated          1  \n..                          ...        ...  \n189       priority to worst off          1  \n190       priority to worst off          1  \n191               not indicated          1  \n192  proportional to commitment          1  \n193               not indicated          1  \n\n[194 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>text</th>\n      <th>PRINCIPLE_x</th>\n      <th>TOPIC_x</th>\n      <th>UNIT_x</th>\n      <th>SHAPE_x</th>\n      <th>llm_query</th>\n      <th>PRINCIPLE_y</th>\n      <th>TOPIC_y</th>\n      <th>UNIT_y</th>\n      <th>SHAPE_y</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Mr. President:  A fair and effective framewor...</td>\n      <td>utilitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>3  Mr. President:  A fair and effective framew...</td>\n      <td>egalitarian</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>Such a framework must be based on “nationally ...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equity</td>\n      <td>5 Such a framework must be based on “nationall...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44</td>\n      <td>It should not only enable us to discuss global...</td>\n      <td>utilitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>44 It should not only enable us to discuss glo...</td>\n      <td>utilitarian</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Global warming is a catastrophic problem that ...</td>\n      <td>utilitarian</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>53 Global warming is a catastrophic problem th...</td>\n      <td>utilitarian</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>54</td>\n      <td>Therefore, the multilateralism approach remain...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>54 Therefore, the multilateralism approach rem...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>1172</td>\n      <td>As we work to catch up on lost time and progr...</td>\n      <td>prioritarian</td>\n      <td>urgency</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1172  As we work to catch up on lost time and ...</td>\n      <td>prioritarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>priority to worst off</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>1173</td>\n      <td>Conflict -ridden communities, refugees, and d...</td>\n      <td>prioritarian</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1173  Conflict -ridden communities, refugees, ...</td>\n      <td>prioritarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>priority to worst off</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>191</th>\n      <td>1174</td>\n      <td>Nor can we stand by , as the massive destructi...</td>\n      <td>utilitarian</td>\n      <td>other</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1174 Nor can we stand by , as the massive dest...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>1198</td>\n      <td>We recognise that we must deliver on our coll...</td>\n      <td>prioritarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>proportional to commitment</td>\n      <td>1198  We recognise that we must deliver on our...</td>\n      <td>sufficientarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>proportional to commitment</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>1205</td>\n      <td>We need a course correction, and working toge...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1205  We need a course correction, and working...</td>\n      <td>utilitarian</td>\n      <td>cooperation</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>194 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_frequent_except_principle(x):\n",
    "    if x.name in ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y', 'TOPIC_y']:\n",
    "        return Counter(x).most_common(1)[0][0]\n",
    "    return x.iloc[0]  # Keep the first value for other columns\n",
    "\n",
    "# Dictionary to specify aggregation functions for all columns\n",
    "agg_dict_all = {col: most_frequent_except_principle for col in filtered_B4.columns if col != 'unique_id'}\n",
    "\n",
    "# Group by 'unique_id' and apply the aggregation functions\n",
    "filtered_B4_grouped = filtered_B4.groupby('unique_id').agg(agg_dict_all).reset_index()\n",
    "\n",
    "filtered_B4_grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:06.686248Z",
     "end_time": "2024-06-07T22:04:06.793171Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                             precision    recall  f1-score     support\negalitarian                   0.534483  0.645833  0.584906   48.000000\ngeneral normative statement   0.352941  0.193548  0.250000   31.000000\nlibertarian                   0.000000  0.000000  0.000000    1.000000\nprioritarian                  0.833333  0.535714  0.652174   56.000000\nsufficientarian               0.312500  0.714286  0.434783    7.000000\nutilitarian                   0.530303  0.686275  0.598291   51.000000\naccuracy                      0.551546  0.551546  0.551546    0.551546\nmacro avg                     0.427260  0.462609  0.420025  194.000000\nweighted avg                  0.579876  0.551546  0.545894  194.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>egalitarian</th>\n      <td>0.534483</td>\n      <td>0.645833</td>\n      <td>0.584906</td>\n      <td>48.000000</td>\n    </tr>\n    <tr>\n      <th>general normative statement</th>\n      <td>0.352941</td>\n      <td>0.193548</td>\n      <td>0.250000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>libertarian</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>prioritarian</th>\n      <td>0.833333</td>\n      <td>0.535714</td>\n      <td>0.652174</td>\n      <td>56.000000</td>\n    </tr>\n    <tr>\n      <th>sufficientarian</th>\n      <td>0.312500</td>\n      <td>0.714286</td>\n      <td>0.434783</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>utilitarian</th>\n      <td>0.530303</td>\n      <td>0.686275</td>\n      <td>0.598291</td>\n      <td>51.000000</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.551546</td>\n      <td>0.551546</td>\n      <td>0.551546</td>\n      <td>0.551546</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.427260</td>\n      <td>0.462609</td>\n      <td>0.420025</td>\n      <td>194.000000</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.579876</td>\n      <td>0.551546</td>\n      <td>0.545894</td>\n      <td>194.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - principle\n",
    "report_principle = classification_report(filtered_B4_grouped['PRINCIPLE_x'],filtered_B4_grouped['PRINCIPLE_y'], output_dict=True)\n",
    "df_principle = pd.DataFrame(report_principle).transpose()\n",
    "df_principle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:07.488869Z",
     "end_time": "2024-06-07T22:04:07.604913Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                                  precision    recall  f1-score     support\nUNFCCC agreements and principles   0.666667  0.357143  0.465116   28.000000\nadaptation                         0.166667  1.000000  0.285714    1.000000\nadaptation and mitigation          0.625000  0.555556  0.588235    9.000000\ncooperation                        0.386364  0.850000  0.531250   20.000000\nfinancial mechanisms               0.617647  1.000000  0.763636   21.000000\nmitigation                         0.307692  0.666667  0.421053    6.000000\nnew UNFCCC policy                  0.545455  0.387097  0.452830   31.000000\nother                              0.736842  0.325581  0.451613   43.000000\nurgency                            0.575758  0.542857  0.558824   35.000000\naccuracy                           0.530928  0.530928  0.530928    0.530928\nmacro avg                          0.514232  0.631656  0.502030  194.000000\nweighted avg                       0.596635  0.530928  0.519622  194.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>UNFCCC agreements and principles</th>\n      <td>0.666667</td>\n      <td>0.357143</td>\n      <td>0.465116</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>adaptation</th>\n      <td>0.166667</td>\n      <td>1.000000</td>\n      <td>0.285714</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>adaptation and mitigation</th>\n      <td>0.625000</td>\n      <td>0.555556</td>\n      <td>0.588235</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>cooperation</th>\n      <td>0.386364</td>\n      <td>0.850000</td>\n      <td>0.531250</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>financial mechanisms</th>\n      <td>0.617647</td>\n      <td>1.000000</td>\n      <td>0.763636</td>\n      <td>21.000000</td>\n    </tr>\n    <tr>\n      <th>mitigation</th>\n      <td>0.307692</td>\n      <td>0.666667</td>\n      <td>0.421053</td>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>new UNFCCC policy</th>\n      <td>0.545455</td>\n      <td>0.387097</td>\n      <td>0.452830</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>other</th>\n      <td>0.736842</td>\n      <td>0.325581</td>\n      <td>0.451613</td>\n      <td>43.000000</td>\n    </tr>\n    <tr>\n      <th>urgency</th>\n      <td>0.575758</td>\n      <td>0.542857</td>\n      <td>0.558824</td>\n      <td>35.000000</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.530928</td>\n      <td>0.530928</td>\n      <td>0.530928</td>\n      <td>0.530928</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.514232</td>\n      <td>0.631656</td>\n      <td>0.502030</td>\n      <td>194.000000</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.596635</td>\n      <td>0.530928</td>\n      <td>0.519622</td>\n      <td>194.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - principle\n",
    "report_topic = classification_report(filtered_B4_grouped['TOPIC_x'],filtered_B4_grouped['TOPIC_y'],output_dict=True)\n",
    "df_topic = pd.DataFrame(report_topic).transpose()\n",
    "df_topic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:04:08.723592Z",
     "end_time": "2024-06-07T22:04:08.815807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                       precision    recall  f1-score  \\\nfinancial and technological resources   0.461538  0.857143  0.600000   \nfinancial resources                     0.966667  0.966667  0.966667   \nnot indicated                           0.848837  0.737374  0.789189   \nother                                   0.000000  0.000000  0.000000   \nresponsibility                          0.591837  0.707317  0.644444   \nsupport                                 0.500000  0.500000  0.500000   \ntechnological resources                 0.500000  1.000000  0.666667   \naccuracy                                0.747423  0.747423  0.747423   \nmacro avg                               0.552697  0.681214  0.595281   \nweighted avg                            0.760469  0.747423  0.747862   \n\n                                          support  \nfinancial and technological resources    7.000000  \nfinancial resources                     30.000000  \nnot indicated                           99.000000  \nother                                    3.000000  \nresponsibility                          41.000000  \nsupport                                 12.000000  \ntechnological resources                  2.000000  \naccuracy                                 0.747423  \nmacro avg                              194.000000  \nweighted avg                           194.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>financial and technological resources</th>\n      <td>0.461538</td>\n      <td>0.857143</td>\n      <td>0.600000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>financial resources</th>\n      <td>0.966667</td>\n      <td>0.966667</td>\n      <td>0.966667</td>\n      <td>30.000000</td>\n    </tr>\n    <tr>\n      <th>not indicated</th>\n      <td>0.848837</td>\n      <td>0.737374</td>\n      <td>0.789189</td>\n      <td>99.000000</td>\n    </tr>\n    <tr>\n      <th>other</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>responsibility</th>\n      <td>0.591837</td>\n      <td>0.707317</td>\n      <td>0.644444</td>\n      <td>41.000000</td>\n    </tr>\n    <tr>\n      <th>support</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>technological resources</th>\n      <td>0.500000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.747423</td>\n      <td>0.747423</td>\n      <td>0.747423</td>\n      <td>0.747423</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.552697</td>\n      <td>0.681214</td>\n      <td>0.595281</td>\n      <td>194.000000</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.760469</td>\n      <td>0.747423</td>\n      <td>0.747862</td>\n      <td>194.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "#print(classification_report(filtered_B4_grouped['UNIT_x'],filtered_B4_grouped['UNIT_y']))\n",
    "\n",
    "# Evaluate performance of this dataframe - principle\n",
    "report_unit = classification_report(filtered_B4_grouped['UNIT_x'],filtered_B4_grouped['UNIT_y'],output_dict=True)\n",
    "df_unit = pd.DataFrame(report_unit).transpose()\n",
    "df_unit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:06:02.817464Z",
     "end_time": "2024-06-07T22:06:02.896672Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": "                              precision    recall  f1-score     support\nequality                       0.176471  0.666667  0.279070    9.000000\nequity                         0.428571  0.500000  0.461538   12.000000\nneeds based                    0.176471  0.750000  0.285714    4.000000\nnot evaluated                  0.000000  0.000000  0.000000    2.000000\nnot indicated                  0.900000  0.600000  0.720000  120.000000\npriority to worst off          0.500000  0.500000  0.500000   26.000000\nproportional to commitment     0.611111  0.687500  0.647059   16.000000\nproportional to contribution   0.800000  0.800000  0.800000    5.000000\naccuracy                       0.592784  0.592784  0.592784    0.592784\nmacro avg                      0.449078  0.563021  0.461673  194.000000\nweighted avg                   0.733066  0.592784  0.633742  194.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n      <th>support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>equality</th>\n      <td>0.176471</td>\n      <td>0.666667</td>\n      <td>0.279070</td>\n      <td>9.000000</td>\n    </tr>\n    <tr>\n      <th>equity</th>\n      <td>0.428571</td>\n      <td>0.500000</td>\n      <td>0.461538</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>needs based</th>\n      <td>0.176471</td>\n      <td>0.750000</td>\n      <td>0.285714</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>not evaluated</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>not indicated</th>\n      <td>0.900000</td>\n      <td>0.600000</td>\n      <td>0.720000</td>\n      <td>120.000000</td>\n    </tr>\n    <tr>\n      <th>priority to worst off</th>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>0.500000</td>\n      <td>26.000000</td>\n    </tr>\n    <tr>\n      <th>proportional to commitment</th>\n      <td>0.611111</td>\n      <td>0.687500</td>\n      <td>0.647059</td>\n      <td>16.000000</td>\n    </tr>\n    <tr>\n      <th>proportional to contribution</th>\n      <td>0.800000</td>\n      <td>0.800000</td>\n      <td>0.800000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>accuracy</th>\n      <td>0.592784</td>\n      <td>0.592784</td>\n      <td>0.592784</td>\n      <td>0.592784</td>\n    </tr>\n    <tr>\n      <th>macro avg</th>\n      <td>0.449078</td>\n      <td>0.563021</td>\n      <td>0.461673</td>\n      <td>194.000000</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.733066</td>\n      <td>0.592784</td>\n      <td>0.633742</td>\n      <td>194.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "#print(classification_report(filtered_B4_grouped['SHAPE_x'],filtered_B4_grouped['SHAPE_y']))\n",
    "\n",
    "# Evaluate performance of this dataframe - principle\n",
    "report_shape = classification_report(filtered_B4_grouped['SHAPE_x'],filtered_B4_grouped['SHAPE_y'],output_dict=True)\n",
    "df_shape = pd.DataFrame(report_shape).transpose()\n",
    "df_shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T22:08:26.330788Z",
     "end_time": "2024-06-07T22:08:26.421643Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "________________________________________________________________________________________________\n",
    "# B4.1 TEST"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "#B1.0\n",
    "path_B4 = 'STRING_RESULT/B4.1/all_iterations'\n",
    "\n",
    "# Open all dataframes\n",
    "S1 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3644.csv')\n",
    "S2 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_3441.csv')\n",
    "S3 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_280.csv')\n",
    "S4 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_5991.csv')\n",
    "S5 = pd.read_csv(f'{path_B4}/all_iterations_string_T0_7917.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:44:39.054411Z",
     "end_time": "2024-06-07T21:44:39.199295Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "(216, 12)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate if predictions are correctly saved\n",
    "# Combine all dataframes into one\n",
    "B4_full_OG = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full_OG.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:44:39.880226Z",
     "end_time": "2024-06-07T21:44:39.961344Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def filter_dataframe(df, principles=None, units=None, shapes=None, topics=None):\n",
    "    if principles:\n",
    "        df = df[df['PRINCIPLE_y'].isin(principles)]\n",
    "    if units:\n",
    "        df = df[df['UNIT_y'].isin(units)]\n",
    "    if shapes:\n",
    "        df = df[df['SHAPE_y'].isin(shapes)]\n",
    "    if topics:\n",
    "        df = df[df['TOPIC_y'].isin(topic)]\n",
    "    return df\n",
    "\n",
    "principle = ['egalitarian', 'general normative statement', 'not evaluated', 'libertarian', 'not evaluated','prioritarian', 'sufficientarian', 'utilitarian']\n",
    "unit = ['not indicated', 'not evaluated', 'responsibility','financial resources', 'technological resources', 'financial and technological resources', 'support', 'other']\n",
    "shape = ['not indicated', 'not evaluated', 'equity', 'equality','priority to worst off', 'needs based', 'proportional to contribution', 'proportional to commitment']\n",
    "topic = ['new UNFCCC policy', 'UNFCCC agreements and principles', 'urgency', 'cooperation', 'financial mechanisms', 'adaptation', 'mitigation', 'adaptation and mitigation', 'other']\n",
    "\n",
    "S1 = filter_dataframe(S1, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S2 = filter_dataframe(S2, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S3 = filter_dataframe(S3, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S4 = filter_dataframe(S4, principles=principle, units=unit, shapes=shape, topics=topic)\n",
    "S5 = filter_dataframe(S5, principles=principle, units=unit, shapes=shape, topics=topic)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:44:41.216957Z",
     "end_time": "2024-06-07T21:44:41.455317Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________________________________\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "(204, 12)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all dataframes into one\n",
    "B4_full = pd.concat([S1, S2, S3, S4, S5], ignore_index=True)\n",
    "B4_full.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:44:44.267795Z",
     "end_time": "2024-06-07T21:44:44.433861Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "(90, 12)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows to keep only those where the unique_id appears exactly 5 times\n",
    "filtered_B4 = B4_full.groupby('unique_id').filter(lambda x: len(x) == 5)\n",
    "filtered_B4.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:44:46.365694Z",
     "end_time": "2024-06-07T21:44:46.442387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# List of unique_id's that are annotated 5 times\n",
    "unique_ids = filtered_B4['unique_id'].unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:02.371434Z",
     "end_time": "2024-06-07T21:46:02.443201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# Filter all original dataframes to only include sentences that are annotated 5x by other seeds\n",
    "FB1S1 = S1[S1['unique_id'].isin(unique_ids)]\n",
    "FB1S2 = S2[S2['unique_id'].isin(unique_ids)]\n",
    "FB1S3 = S3[S3['unique_id'].isin(unique_ids)]\n",
    "FB1S4 = S4[S4['unique_id'].isin(unique_ids)]\n",
    "FB1S5 = S5[S5['unique_id'].isin(unique_ids)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:02.915951Z",
     "end_time": "2024-06-07T21:46:02.984068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for S1\n",
      "                             precision    recall  f1-score    support\n",
      "egalitarian                   0.500000  0.800000  0.615385   5.000000\n",
      "general normative statement   0.500000  0.142857  0.222222   7.000000\n",
      "libertarian                   0.000000  0.000000  0.000000   1.000000\n",
      "prioritarian                  0.500000  0.500000  0.500000   2.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000   0.000000\n",
      "utilitarian                   0.333333  0.333333  0.333333   3.000000\n",
      "accuracy                      0.388889  0.388889  0.388889   0.388889\n",
      "macro avg                     0.305556  0.296032  0.278490  18.000000\n",
      "weighted avg                  0.444444  0.388889  0.368471  18.000000\n",
      "\n",
      "\n",
      "Classification Report for S2\n",
      "                             precision    recall  f1-score    support\n",
      "egalitarian                   0.444444  0.800000  0.571429   5.000000\n",
      "general normative statement   0.500000  0.142857  0.222222   7.000000\n",
      "libertarian                   0.000000  0.000000  0.000000   1.000000\n",
      "prioritarian                  0.500000  0.500000  0.500000   2.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000   0.000000\n",
      "utilitarian                   0.500000  0.333333  0.400000   3.000000\n",
      "accuracy                      0.388889  0.388889  0.388889   0.388889\n",
      "macro avg                     0.324074  0.296032  0.282275  18.000000\n",
      "weighted avg                  0.456790  0.388889  0.367372  18.000000\n",
      "\n",
      "\n",
      "Classification Report for S3\n",
      "                             precision    recall  f1-score    support\n",
      "egalitarian                   0.444444  0.800000  0.571429   5.000000\n",
      "general normative statement   0.500000  0.142857  0.222222   7.000000\n",
      "libertarian                   0.000000  0.000000  0.000000   1.000000\n",
      "prioritarian                  0.500000  0.500000  0.500000   2.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000   0.000000\n",
      "utilitarian                   0.500000  0.333333  0.400000   3.000000\n",
      "accuracy                      0.388889  0.388889  0.388889   0.388889\n",
      "macro avg                     0.324074  0.296032  0.282275  18.000000\n",
      "weighted avg                  0.456790  0.388889  0.367372  18.000000\n",
      "\n",
      "\n",
      "Classification Report for S4\n",
      "                             precision    recall  f1-score    support\n",
      "egalitarian                   0.444444  0.800000  0.571429   5.000000\n",
      "general normative statement   0.500000  0.142857  0.222222   7.000000\n",
      "libertarian                   0.000000  0.000000  0.000000   1.000000\n",
      "prioritarian                  0.500000  0.500000  0.500000   2.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000   0.000000\n",
      "utilitarian                   0.500000  0.333333  0.400000   3.000000\n",
      "accuracy                      0.388889  0.388889  0.388889   0.388889\n",
      "macro avg                     0.324074  0.296032  0.282275  18.000000\n",
      "weighted avg                  0.456790  0.388889  0.367372  18.000000\n",
      "\n",
      "\n",
      "Classification Report for S5\n",
      "                             precision    recall  f1-score    support\n",
      "egalitarian                   0.444444  0.800000  0.571429   5.000000\n",
      "general normative statement   0.500000  0.142857  0.222222   7.000000\n",
      "libertarian                   0.000000  0.000000  0.000000   1.000000\n",
      "prioritarian                  0.500000  0.500000  0.500000   2.000000\n",
      "sufficientarian               0.000000  0.000000  0.000000   0.000000\n",
      "utilitarian                   0.500000  0.333333  0.400000   3.000000\n",
      "accuracy                      0.388889  0.388889  0.388889   0.388889\n",
      "macro avg                     0.324074  0.296032  0.282275  18.000000\n",
      "weighted avg                  0.456790  0.388889  0.367372  18.000000\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of individual seeds for the same sentences\n",
    "# Function to generate classification report for each dataframe\n",
    "def generate_classification_report(df, true_label_col, pred_label_col):\n",
    "    return classification_report(df[true_label_col], df[pred_label_col], output_dict=True)\n",
    "\n",
    "# Generate classification reports\n",
    "report_S1 = generate_classification_report(FB1S1, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S2 = generate_classification_report(FB1S2, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S3 = generate_classification_report(FB1S3, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S4 = generate_classification_report(FB1S4, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "report_S5 = generate_classification_report(FB1S5, 'PRINCIPLE_x', 'PRINCIPLE_y')\n",
    "\n",
    "# Function to print the classification reports for easy comparison\n",
    "def print_classification_report(report, title):\n",
    "    print(f\"Classification Report for {title}\")\n",
    "    print(pd.DataFrame(report).transpose())\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print the classification reports\n",
    "print_classification_report(report_S1, \"S1\")\n",
    "print_classification_report(report_S2, \"S2\")\n",
    "print_classification_report(report_S3, \"S3\")\n",
    "print_classification_report(report_S4, \"S4\")\n",
    "print_classification_report(report_S5, \"S5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:03.495846Z",
     "end_time": "2024-06-07T21:46:03.623830Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate consistency of predictions over the 5 different instances - see which sentences are not consistantly predicted.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "(30, 12)"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def columns_not_uniform(group, columns):\n",
    "    for col in columns:\n",
    "        if group[col].nunique() != 1:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Columns to check for uniformity\n",
    "columns_to_check = ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y','TOPIC_y']\n",
    "\n",
    "# Group by 'unique_id' and filter groups\n",
    "B4_consistency = filtered_B4.groupby('unique_id').filter(lambda x: columns_not_uniform(x, columns_to_check))\n",
    "\n",
    "B4_consistency.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:06.208046Z",
     "end_time": "2024-06-07T21:46:06.474953Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "In combined dataframe, groupyby unique ID and take the majority label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "    unique_id                                               text  \\\n0          14  We have advocated a structure for the new agre...   \n1          15  •  This kind of structure, based on a spectrum...   \n2          16  •  By contrast, an agreement based on 1992 cat...   \n3          18  If those categories are to beoperational in ch...   \n4          25  •  Let us work together, mindful of our mutual...   \n5          35  The major polluters, especially those who are ...   \n6          38  Pledges to the Green Climate Fund have now pas...   \n7          40  We call on our partners to deliver the large s...   \n8          41  Loss and damage should also be included as an ...   \n9          44  We also fully support inclusion of gender equa...   \n10         45  Full and equal participation of women in all c...   \n11         52  We must all take every opportunity to cooperat...   \n12         66  Therefore, I urge all parties to ensure that t...   \n13         75  Therefore, I call upon alldeveloped countries ...   \n14         77  As Lord Buddha said, we are here not to blame ...   \n15         87  As we move forward , we must employ an inclusi...   \n16         88  This, however, requires predictable , adequate...   \n17         95        This requires global commitment and action.   \n\n                    PRINCIPLE_x                           TOPIC_x  \\\n0                   egalitarian                 new UNFCCC policy   \n1                   utilitarian  UNFCCC agreements and principles   \n2                   libertarian  UNFCCC agreements and principles   \n3   general normative statement                 new UNFCCC policy   \n4                   egalitarian                       cooperation   \n5   general normative statement  UNFCCC agreements and principles   \n6                  prioritarian              financial mechanisms   \n7   general normative statement              financial mechanisms   \n8   general normative statement                             other   \n9                   egalitarian                             other   \n10                  egalitarian                             other   \n11  general normative statement                       cooperation   \n12                  utilitarian  UNFCCC agreements and principles   \n13                 prioritarian              financial mechanisms   \n14                  utilitarian                 new UNFCCC policy   \n15  general normative statement                 new UNFCCC policy   \n16  general normative statement                 new UNFCCC policy   \n17                  egalitarian                 new UNFCCC policy   \n\n                 UNIT_x                       SHAPE_x  \\\n0        responsibility                      equality   \n1        responsibility                        equity   \n2         not indicated                 not indicated   \n3        responsibility                        equity   \n4        responsibility                 not indicated   \n5        responsibility  proportional to contribution   \n6   financial resources         priority to worst off   \n7   financial resources                 not indicated   \n8         not indicated                 not indicated   \n9         not indicated                 not indicated   \n10        not indicated                 not indicated   \n11       responsibility                 not indicated   \n12       responsibility                 not indicated   \n13  financial resources         priority to worst off   \n14        not indicated                        equity   \n15        not indicated                 not indicated   \n16        not indicated                 not indicated   \n17       responsibility                      equality   \n\n                                            llm_query  \\\n0   14 We have advocated a structure for the new a...   \n1   15 •  This kind of structure, based on a spect...   \n2   16 •  By contrast, an agreement based on 1992 ...   \n3   18 If those categories are to beoperational in...   \n4   25 •  Let us work together, mindful of our mut...   \n5   35 The major polluters, especially those who a...   \n6   38 Pledges to the Green Climate Fund have now ...   \n7   40 We call on our partners to deliver the larg...   \n8   41 Loss and damage should also be included as ...   \n9   44 We also fully support inclusion of gender e...   \n10  45 Full and equal participation of women in al...   \n11  52 We must all take every opportunity to coope...   \n12  66 Therefore, I urge all parties to ensure tha...   \n13  75 Therefore, I call upon alldeveloped countri...   \n14  77 As Lord Buddha said, we are here not to bla...   \n15  87 As we move forward , we must employ an incl...   \n16  88 This, however, requires predictable , adequ...   \n17   95 This requires global commitment and action.\\n   \n\n                    PRINCIPLE_y               TOPIC_y               UNIT_y  \\\n0                   egalitarian     new UNFCCC policy       responsibility   \n1                   egalitarian            mitigation       responsibility   \n2   general normative statement     new UNFCCC policy        not indicated   \n3                   egalitarian     new UNFCCC policy       responsibility   \n4                   egalitarian           cooperation       responsibility   \n5                  prioritarian               urgency       responsibility   \n6               sufficientarian  financial mechanisms  financial resources   \n7               sufficientarian  financial mechanisms  financial resources   \n8   general normative statement     new UNFCCC policy        not indicated   \n9                   egalitarian     new UNFCCC policy       responsibility   \n10                  egalitarian     new UNFCCC policy       responsibility   \n11                  egalitarian           cooperation       responsibility   \n12                  utilitarian               urgency       responsibility   \n13                 prioritarian  financial mechanisms  financial resources   \n14                  egalitarian           cooperation       responsibility   \n15                  egalitarian            adaptation       responsibility   \n16              sufficientarian  financial mechanisms  financial resources   \n17                  utilitarian               urgency       responsibility   \n\n                  SHAPE_y  iteration  \n0                equality          1  \n1                  equity          1  \n2           not indicated          1  \n3                  equity          1  \n4                equality          1  \n5   priority to worst off          1  \n6             needs based          1  \n7             needs based          1  \n8           not indicated          1  \n9                equality          1  \n10               equality          1  \n11               equality          1  \n12          not indicated          1  \n13  priority to worst off          1  \n14               equality          1  \n15               equality          1  \n16            needs based          1  \n17          not indicated          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>text</th>\n      <th>PRINCIPLE_x</th>\n      <th>TOPIC_x</th>\n      <th>UNIT_x</th>\n      <th>SHAPE_x</th>\n      <th>llm_query</th>\n      <th>PRINCIPLE_y</th>\n      <th>TOPIC_y</th>\n      <th>UNIT_y</th>\n      <th>SHAPE_y</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14</td>\n      <td>We have advocated a structure for the new agre...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>14 We have advocated a structure for the new a...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>•  This kind of structure, based on a spectrum...</td>\n      <td>utilitarian</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>responsibility</td>\n      <td>equity</td>\n      <td>15 •  This kind of structure, based on a spect...</td>\n      <td>egalitarian</td>\n      <td>mitigation</td>\n      <td>responsibility</td>\n      <td>equity</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>•  By contrast, an agreement based on 1992 cat...</td>\n      <td>libertarian</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>16 •  By contrast, an agreement based on 1992 ...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>If those categories are to beoperational in ch...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equity</td>\n      <td>18 If those categories are to beoperational in...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equity</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>25</td>\n      <td>•  Let us work together, mindful of our mutual...</td>\n      <td>egalitarian</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>not indicated</td>\n      <td>25 •  Let us work together, mindful of our mut...</td>\n      <td>egalitarian</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>35</td>\n      <td>The major polluters, especially those who are ...</td>\n      <td>general normative statement</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>responsibility</td>\n      <td>proportional to contribution</td>\n      <td>35 The major polluters, especially those who a...</td>\n      <td>prioritarian</td>\n      <td>urgency</td>\n      <td>responsibility</td>\n      <td>priority to worst off</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>38</td>\n      <td>Pledges to the Green Climate Fund have now pas...</td>\n      <td>prioritarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>priority to worst off</td>\n      <td>38 Pledges to the Green Climate Fund have now ...</td>\n      <td>sufficientarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>needs based</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>40</td>\n      <td>We call on our partners to deliver the large s...</td>\n      <td>general normative statement</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>not indicated</td>\n      <td>40 We call on our partners to deliver the larg...</td>\n      <td>sufficientarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>needs based</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>41</td>\n      <td>Loss and damage should also be included as an ...</td>\n      <td>general normative statement</td>\n      <td>other</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>41 Loss and damage should also be included as ...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>44</td>\n      <td>We also fully support inclusion of gender equa...</td>\n      <td>egalitarian</td>\n      <td>other</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>44 We also fully support inclusion of gender e...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>45</td>\n      <td>Full and equal participation of women in all c...</td>\n      <td>egalitarian</td>\n      <td>other</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>45 Full and equal participation of women in al...</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>52</td>\n      <td>We must all take every opportunity to cooperat...</td>\n      <td>general normative statement</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>not indicated</td>\n      <td>52 We must all take every opportunity to coope...</td>\n      <td>egalitarian</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>66</td>\n      <td>Therefore, I urge all parties to ensure that t...</td>\n      <td>utilitarian</td>\n      <td>UNFCCC agreements and principles</td>\n      <td>responsibility</td>\n      <td>not indicated</td>\n      <td>66 Therefore, I urge all parties to ensure tha...</td>\n      <td>utilitarian</td>\n      <td>urgency</td>\n      <td>responsibility</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>75</td>\n      <td>Therefore, I call upon alldeveloped countries ...</td>\n      <td>prioritarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>priority to worst off</td>\n      <td>75 Therefore, I call upon alldeveloped countri...</td>\n      <td>prioritarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>priority to worst off</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>77</td>\n      <td>As Lord Buddha said, we are here not to blame ...</td>\n      <td>utilitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>equity</td>\n      <td>77 As Lord Buddha said, we are here not to bla...</td>\n      <td>egalitarian</td>\n      <td>cooperation</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>87</td>\n      <td>As we move forward , we must employ an inclusi...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>87 As we move forward , we must employ an incl...</td>\n      <td>egalitarian</td>\n      <td>adaptation</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>88</td>\n      <td>This, however, requires predictable , adequate...</td>\n      <td>general normative statement</td>\n      <td>new UNFCCC policy</td>\n      <td>not indicated</td>\n      <td>not indicated</td>\n      <td>88 This, however, requires predictable , adequ...</td>\n      <td>sufficientarian</td>\n      <td>financial mechanisms</td>\n      <td>financial resources</td>\n      <td>needs based</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>95</td>\n      <td>This requires global commitment and action.</td>\n      <td>egalitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n      <td>95 This requires global commitment and action.\\n</td>\n      <td>utilitarian</td>\n      <td>urgency</td>\n      <td>responsibility</td>\n      <td>not indicated</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_frequent_except_principle(x):\n",
    "    if x.name in ['PRINCIPLE_y', 'UNIT_y', 'SHAPE_y', 'TOPIC_y']:\n",
    "        return Counter(x).most_common(1)[0][0]\n",
    "    return x.iloc[0]  # Keep the first value for other columns\n",
    "\n",
    "# Dictionary to specify aggregation functions for all columns\n",
    "agg_dict_all = {col: most_frequent_except_principle for col in filtered_B4.columns if col != 'unique_id'}\n",
    "\n",
    "# Group by 'unique_id' and apply the aggregation functions\n",
    "filtered_B4_grouped = filtered_B4.groupby('unique_id').agg(agg_dict_all).reset_index()\n",
    "\n",
    "filtered_B4_grouped"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:24.540617Z",
     "end_time": "2024-06-07T21:46:24.665823Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             precision    recall  f1-score   support\n",
      "\n",
      "                egalitarian       0.44      0.80      0.57         5\n",
      "general normative statement       0.50      0.14      0.22         7\n",
      "                libertarian       0.00      0.00      0.00         1\n",
      "               prioritarian       0.50      0.50      0.50         2\n",
      "            sufficientarian       0.00      0.00      0.00         0\n",
      "                utilitarian       0.50      0.33      0.40         3\n",
      "\n",
      "                   accuracy                           0.39        18\n",
      "                  macro avg       0.32      0.30      0.28        18\n",
      "               weighted avg       0.46      0.39      0.37        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - principle\n",
    "print(classification_report(filtered_B4_grouped['PRINCIPLE_x'],filtered_B4_grouped['PRINCIPLE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:25.561792Z",
     "end_time": "2024-06-07T21:46:25.648339Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "UNFCCC agreements and principles       0.00      0.00      0.00         4\n",
      "                      adaptation       0.00      0.00      0.00         0\n",
      "                     cooperation       0.67      1.00      0.80         2\n",
      "            financial mechanisms       0.75      1.00      0.86         3\n",
      "                      mitigation       0.00      0.00      0.00         0\n",
      "               new UNFCCC policy       0.33      0.33      0.33         6\n",
      "                           other       0.00      0.00      0.00         3\n",
      "                         urgency       0.00      0.00      0.00         0\n",
      "\n",
      "                        accuracy                           0.39        18\n",
      "                       macro avg       0.22      0.29      0.25        18\n",
      "                    weighted avg       0.31      0.39      0.34        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['TOPIC_x'],filtered_B4_grouped['TOPIC_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:28.042935Z",
     "end_time": "2024-06-07T21:46:28.138858Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     precision    recall  f1-score   support\n",
      "\n",
      "financial resources       0.75      1.00      0.86         3\n",
      "      not indicated       1.00      0.29      0.44         7\n",
      "     responsibility       0.67      1.00      0.80         8\n",
      "\n",
      "           accuracy                           0.72        18\n",
      "          macro avg       0.81      0.76      0.70        18\n",
      "       weighted avg       0.81      0.72      0.67        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['UNIT_x'],filtered_B4_grouped['UNIT_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:29.126899Z",
     "end_time": "2024-06-07T21:46:29.215282Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              precision    recall  f1-score   support\n",
      "\n",
      "                    equality       0.14      0.50      0.22         2\n",
      "                      equity       1.00      0.67      0.80         3\n",
      "                 needs based       0.00      0.00      0.00         0\n",
      "               not indicated       0.75      0.30      0.43        10\n",
      "       priority to worst off       0.50      0.50      0.50         2\n",
      "proportional to contribution       0.00      0.00      0.00         1\n",
      "\n",
      "                    accuracy                           0.39        18\n",
      "                   macro avg       0.40      0.33      0.33        18\n",
      "                weighted avg       0.65      0.39      0.45        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\App\\Python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate performance of this dataframe - topic\n",
    "print(classification_report(filtered_B4_grouped['SHAPE_x'],filtered_B4_grouped['SHAPE_y']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-06-07T21:46:30.585879Z",
     "end_time": "2024-06-07T21:46:30.800868Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
