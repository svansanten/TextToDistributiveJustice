{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:38.895615Z",
     "end_time": "2024-05-28T15:13:38.917303Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook to annotate HLS speeches for relevance\n",
    "### B: string-based labels\n",
    "\n",
    "Codebooks:\n",
    "- B1.0: zero shot\n",
    "- B1.1: one shot\n",
    "- B1.2: two shot\n",
    "\n",
    "- B1.1.1: one shot with specific inclusion of context\n",
    "\n",
    "Test for 5 different seeds\n",
    "Batch of 20 sentences\n",
    "Original: 5 iterations; does take very long!\n",
    "Set to 1 iteration; check for class imbalances between labelled elements. OOK: seed zou moeten zorgen dat iedere iteratie gelijk is - dit hoeft niet het geval te zijn, zeker niet als de temperature is aangepast. > kan wel inherent in model zitten\n",
    "\n",
    "Main outcomes: T0 - I1\n",
    "For testing purposes: T0 - T 0.2 - T 0.6 : I3\n",
    "\n",
    "Temperature: 0 - 0.6\n",
    "Temperature only focuses on the output probabilities - should thus be set to 0 to make the output as deterministic as possible.\n",
    "> Do a single test to see what the influence of changing temperature is\n",
    "> Top_p is set to 1; making temperature the primary factor.\n",
    "\n",
    "Hypothesis: accuracy decreases with temperature\n",
    "\n",
    "Model selection:\n",
    " As of 22-05-2024, gpt-4-turbo-2024-04-09 seems to be the only gpt-model that returns a fingerprint in addition to gpt-4o\n",
    "\n",
    "  #model= \"gpt-4-turbo-2024-04-09\"\n",
    "  #model = \"gpt-3.5-turbo-0125\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import text to annotate\n",
    "Select only relevant columns of the full dataframe, in this case:\n",
    "RELEVANCE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import string based datafile\n",
    "HLS_train = pd.read_csv('data/string/HLS_train_string.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:42.290012Z",
     "end_time": "2024-05-28T15:13:42.320490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                    id                                               Text  \\\n0          COP19_japan                         Thank you, Mr. President .   \n1          COP19_japan   On beha lf of the government of Japan , I wou...   \n2          COP19_japan   I would also like to expr ess my d eepest con...   \n3          COP19_japan   Mr. President:  A fair and effective framewor...   \n4          COP19_japan   In this regard, Japan firmly supports the est...   \n...                ...                                                ...   \n1207  COP28_newzealand   New Zealand is proud to suppor t several impo...   \n1208  COP28_newzealand  I am joined by New Zealand’s largest business,...   \n1209  COP28_newzealand  The commitment o f New Zealanders from across ...   \n1210  COP28_newzealand                            Thank you Mr President.   \n1211  COP28_newzealand                                          Kia Kaha    \n\n      Relevance  Principle  Topic  Unit  Shape            RELEVANCE  \\\n0             0          0      0     0      0         Not relevant   \n1             0          0      0     0      0         Not relevant   \n2             0          0      0     0      0         Not relevant   \n3             2          3      1     2      2             Relevant   \n4             1          0      0     0      0  Statement of intent   \n...         ...        ...    ...   ...    ...                  ...   \n1207          0          0      0     0      0         Not relevant   \n1208          0          0      0     0      0         Not relevant   \n1209          0          0      0     0      0         Not relevant   \n1210          0          0      0     0      0         Not relevant   \n1211          0          0      0     0      0         Not relevant   \n\n          PRINCIPLE              TOPIC            UNIT          SHAPE  \n0     not evaluated      not evaluated   not evaluated  not evaluated  \n1     not evaluated      not evaluated   not evaluated  not evaluated  \n2     not evaluated      not evaluated   not evaluated  not evaluated  \n3       utilitarian  new UNFCCC policy  responsibility       equality  \n4     not evaluated      not evaluated   not evaluated  not evaluated  \n...             ...                ...             ...            ...  \n1207  not evaluated      not evaluated   not evaluated  not evaluated  \n1208  not evaluated      not evaluated   not evaluated  not evaluated  \n1209  not evaluated      not evaluated   not evaluated  not evaluated  \n1210  not evaluated      not evaluated   not evaluated  not evaluated  \n1211  not evaluated      not evaluated   not evaluated  not evaluated  \n\n[1212 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Text</th>\n      <th>Relevance</th>\n      <th>Principle</th>\n      <th>Topic</th>\n      <th>Unit</th>\n      <th>Shape</th>\n      <th>RELEVANCE</th>\n      <th>PRINCIPLE</th>\n      <th>TOPIC</th>\n      <th>UNIT</th>\n      <th>SHAPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COP19_japan</td>\n      <td>Thank you, Mr. President .</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>COP19_japan</td>\n      <td>On beha lf of the government of Japan , I wou...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>COP19_japan</td>\n      <td>I would also like to expr ess my d eepest con...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>COP19_japan</td>\n      <td>Mr. President:  A fair and effective framewor...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Relevant</td>\n      <td>utilitarian</td>\n      <td>new UNFCCC policy</td>\n      <td>responsibility</td>\n      <td>equality</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>COP19_japan</td>\n      <td>In this regard, Japan firmly supports the est...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Statement of intent</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>COP28_newzealand</td>\n      <td>New Zealand is proud to suppor t several impo...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>COP28_newzealand</td>\n      <td>I am joined by New Zealand’s largest business,...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>COP28_newzealand</td>\n      <td>The commitment o f New Zealanders from across ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>COP28_newzealand</td>\n      <td>Thank you Mr President.</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>COP28_newzealand</td>\n      <td>Kia Kaha</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Not relevant</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n      <td>not evaluated</td>\n    </tr>\n  </tbody>\n</table>\n<p>1212 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Select only japan for testing purposes\n",
    "#HLS_train_japan = HLS_train[HLS_train['id']=='COP19_japan']\n",
    "HLS_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:42.778550Z",
     "end_time": "2024-05-28T15:13:42.827543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Select only columns containing relevance labels\n",
    "HLS_relevance = HLS_train[['Text', 'RELEVANCE']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:43.728504Z",
     "end_time": "2024-05-28T15:13:43.735488Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import necessary files\n",
    "- codebooks\n",
    "- API key\n",
    "- import gpt_annotate_num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load codebook - zero shot\n",
    "with open('codebooks/B1.0', 'r', encoding='utf-8') as file:\n",
    "    B10 = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:45.801072Z",
     "end_time": "2024-05-28T15:13:45.840826Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# OpenAI key\n",
    "with open('gpt_api_key.txt', 'r') as f:\n",
    "    key = f.read().strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:46.284707Z",
     "end_time": "2024-05-28T15:13:46.297696Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import gpt_annotate_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:13:46.749993Z",
     "end_time": "2024-05-28T15:14:01.603452Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for annotation\n",
    "Compares column names in HLS_relevance to the codes identified by GPT-4o in the codebook. Seed for this identification is set to 1234."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9TqwPCRvN3vhQGbaq5TbVxnJsKZxW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='RELEVANCE', role='assistant', function_call=None, tool_calls=None))], created=1716902045, model='gpt-4o-2024-05-13', object='chat.completion', system_fingerprint='fp_43dfabdef1', usage=CompletionUsage(completion_tokens=3, prompt_tokens=332, total_tokens=335))\n",
      "\n",
      "Categories to annotate:\n",
      "1) RELEVANCE\n",
      "\n",
      "\n",
      "Data is ready to be annotated using gpt_annotate()!\n",
      "\n",
      "Glimpse of your data:\n",
      "Shape of data:  (1212, 4)\n",
      "   unique_id                                               text  \\\n",
      "0          0                         Thank you, Mr. President .   \n",
      "1          1   On beha lf of the government of Japan , I wou...   \n",
      "2          2   I would also like to expr ess my d eepest con...   \n",
      "3          3   Mr. President:  A fair and effective framewor...   \n",
      "4          4   In this regard, Japan firmly supports the est...   \n",
      "\n",
      "             RELEVANCE                                          llm_query  \n",
      "0         Not relevant                    0  Thank you, Mr. President .\\n  \n",
      "1         Not relevant  1  On beha lf of the government of Japan , I w...  \n",
      "2         Not relevant  2  I would also like to expr ess my d eepest c...  \n",
      "3             Relevant  3  Mr. President:  A fair and effective framew...  \n",
      "4  Statement of intent  4  In this regard, Japan firmly supports the e...  \n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for annotation\n",
    "text_to_annotate = gpt_annotate_string.prepare_data(HLS_relevance, B10, key, prep_codebook=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:04.751972Z",
     "end_time": "2024-05-28T15:14:07.342962Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fingerprint used: fp_43dfabdef1\n",
    "\n",
    "Seed of textpreparation is hardcoded into gpt_annotate. This to ensure that onlye the results of the same fingerprint for all seeds and all iterations. Essentially every time GPT-4o is called only results with this specific fingerprint are saved."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run gpt_annotate_num\n",
    "Evaluation per seed -\n",
    "5 different seeds\n",
    "Batch of 20 sentences\n",
    "5 iterations\n",
    "\n",
    "Returns 3 outputs:\n",
    "1. all_iterations_{seed}.csv\n",
    "2. fingerprints_all.csv\n",
    "3. missed_batches.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "fingerprint = 'fp_43dfabdef1'\n",
    "seeds = [3644,3441, 280, 5991, 7917]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:16.363155Z",
     "end_time": "2024-05-28T15:14:16.384832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644 - iteration 1\n",
      "3644 - I1 - B5 fingerprint does not match\n",
      "3644 - I1 - B8 fingerprint does not match\n",
      "3644 - I1 - B12 fingerprint does not match\n",
      "3644 - I1 - B38 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "3441 - iteration 1\n",
      "3441 - I1 - B8 fingerprint does not match\n",
      "3441 - I1 - B26 fingerprint does not match\n",
      "3441 - I1 - B27 fingerprint does not match\n",
      "3441 - I1 - B45 fingerprint does not match\n",
      "3441 - I1 - B61 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "280 - iteration 1\n",
      "280 - I1 - B29 fingerprint does not match\n",
      "280 - I1 - B30 fingerprint does not match\n",
      "280 - I1 - B38 fingerprint does not match\n",
      "280 - I1 - B58 fingerprint does not match\n",
      "280 - I1 - B60 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "5991 - iteration 1\n",
      "5991 - I1 - B8 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "7917 - iteration 1\n",
      "7917 - I1 - B7 fingerprint does not match\n",
      "7917 - I1 - B20 fingerprint does not match\n",
      "7917 - I1 - B22 fingerprint does not match\n",
      "7917 - I1 - B46 fingerprint does not match\n",
      "7917 - I1 - B61 fingerprint does not match\n",
      "iteration:  1 completed\n"
     ]
    }
   ],
   "source": [
    "# Annotate the data - T0 - I1\n",
    "for seed in seeds:\n",
    "    gpt_annotate_string.gpt_annotate(text_to_annotate, B10, key, seed,fingerprint, experiment=\"B1.0\",  num_iterations=1, model=\"gpt-4o\", temperature=0, batch_size=20, human_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T12:29:34.825030Z",
     "end_time": "2024-05-28T12:45:38.983990Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate with temperature 0.6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644 - iteration 1\n",
      "3644 - I1 - B5 fingerprint does not match\n",
      "3644 - I1 - B26 fingerprint does not match\n",
      "3644 - I1 - B39 fingerprint does not match\n",
      "3644 - I1 - B55 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "3441 - iteration 1\n",
      "3441 - I1 - B22 fingerprint does not match\n",
      "3441 - I1 - B29 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "280 - iteration 1\n",
      "280 - I1 - B1 fingerprint does not match\n",
      "280 - I1 - B33 fingerprint does not match\n",
      "280 - I1 - B42 fingerprint does not match\n",
      "280 - I1 - B54 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "5991 - iteration 1\n",
      "5991 - I1 - B32 fingerprint does not match\n",
      "5991 - I1 - B43 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "7917 - iteration 1\n",
      "7917 - I1 - B1 fingerprint does not match\n",
      "7917 - I1 - B12 fingerprint does not match\n",
      "7917 - I1 - B32 fingerprint does not match\n",
      "iteration:  1 completed\n"
     ]
    }
   ],
   "source": [
    "# Annotate the data - T0 - I1\n",
    "for seed in seeds:\n",
    "    gpt_annotate_string.gpt_annotate(text_to_annotate, B10, key, seed,fingerprint, experiment=\"B1.0\",  num_iterations=1, model=\"gpt-4o\", temperature=0.6, batch_size=20, human_labels=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate accuracy of predictions\n",
    "Based on similarity between predicted and true labels.\n",
    "Currently not taking consistency into account - would be done by grouping\n",
    "\n",
    "\n",
    "Define function for similarity score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_similarity_score(Rx, Ry):\n",
    "    # Ensure Rx and Ry are pandas Series and convert to strings with stripped whitespace\n",
    "    Rx = Rx.astype(str).str.strip()\n",
    "    Ry = Ry.astype(str).str.strip()\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = Rx.combine(Ry, lambda x, y: difflib.SequenceMatcher(None, x, y).ratio())\n",
    "\n",
    "    # Apply the threshold - maybe put higher?\n",
    "    similarity_scores = similarity_scores.apply(lambda x: x if x >= 0.9 else 0)\n",
    "\n",
    "    # Return the mean similarity score as a percentage\n",
    "    return similarity_scores.mean() * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:22.314056Z",
     "end_time": "2024-05-28T15:14:22.325877Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                              filename  similarity ALL\n0   all_iterations_string_T0.6_280.csv       58.922261\n1  all_iterations_string_T0.6_3441.csv       59.556314\n2  all_iterations_string_T0.6_3644.csv       59.540636\n3  all_iterations_string_T0.6_5991.csv       58.617747\n4  all_iterations_string_T0.6_7917.csv       59.635417\n5     all_iterations_string_T0_280.csv       59.442446\n6    all_iterations_string_T0_3441.csv       60.089286\n7    all_iterations_string_T0_3644.csv       59.628975\n8    all_iterations_string_T0_5991.csv       60.822148\n9    all_iterations_string_T0_7917.csv       60.982143",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>similarity ALL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0.6_280.csv</td>\n      <td>58.922261</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0.6_3441.csv</td>\n      <td>59.556314</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0.6_3644.csv</td>\n      <td>59.540636</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0.6_5991.csv</td>\n      <td>58.617747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0.6_7917.csv</td>\n      <td>59.635417</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>59.442446</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>60.089286</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>59.628975</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>60.822148</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>60.982143</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through each file in the directory\n",
    "directory = 'STRING_RESULT/B1.0/all_iterations'\n",
    "similarity_scores_all = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    Rx = df['RELEVANCE_x']\n",
    "    Ry = df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_all.append((filename, similarity_score))\n",
    "\n",
    "similarity_all = pd.DataFrame(similarity_scores_all, columns=['filename', 'similarity ALL'])\n",
    "similarity_all.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_all\", index=False)\n",
    "\n",
    "similarity_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:34.918874Z",
     "end_time": "2024-05-28T15:14:36.085882Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                              filename  Similarity RELEVANT\n0   all_iterations_string_T0.6_280.csv            79.611650\n1  all_iterations_string_T0.6_3441.csv            80.555556\n2  all_iterations_string_T0.6_3644.csv            84.577114\n3  all_iterations_string_T0.6_5991.csv            75.961538\n4  all_iterations_string_T0.6_7917.csv            79.710145\n5     all_iterations_string_T0_280.csv            76.076555\n6    all_iterations_string_T0_3441.csv            81.122449\n7    all_iterations_string_T0_3644.csv            79.104478\n8    all_iterations_string_T0_5991.csv            81.042654\n9    all_iterations_string_T0_7917.csv            77.272727",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity RELEVANT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0.6_280.csv</td>\n      <td>79.611650</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0.6_3441.csv</td>\n      <td>80.555556</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0.6_3644.csv</td>\n      <td>84.577114</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0.6_5991.csv</td>\n      <td>75.961538</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0.6_7917.csv</td>\n      <td>79.710145</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>76.076555</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>81.122449</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>79.104478</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>81.042654</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>77.272727</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_relevant = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_relevant.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "similarity_relevant = pd.DataFrame(similarity_scores_relevant, columns=['filename', 'Similarity RELEVANT'])\n",
    "similarity_relevant.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_relevant\", index=False)\n",
    "\n",
    "similarity_relevant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:40.572846Z",
     "end_time": "2024-05-28T15:14:40.817789Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                              filename  Similarity SOI\n0   all_iterations_string_T0.6_280.csv       53.571429\n1  all_iterations_string_T0.6_3441.csv       52.604167\n2  all_iterations_string_T0.6_3644.csv       49.746193\n3  all_iterations_string_T0.6_5991.csv       52.040816\n4  all_iterations_string_T0.6_7917.csv       55.384615\n5     all_iterations_string_T0_280.csv       53.804348\n6    all_iterations_string_T0_3441.csv       52.736318\n7    all_iterations_string_T0_3644.csv       55.778894\n8    all_iterations_string_T0_5991.csv       54.807692\n9    all_iterations_string_T0_7917.csv       56.185567",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity SOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0.6_280.csv</td>\n      <td>53.571429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0.6_3441.csv</td>\n      <td>52.604167</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0.6_3644.csv</td>\n      <td>49.746193</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0.6_5991.csv</td>\n      <td>52.040816</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0.6_7917.csv</td>\n      <td>55.384615</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>53.804348</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>52.736318</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>55.778894</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>54.807692</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>56.185567</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_SOI = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Statement of intent']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_SOI.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "similarity_SOI = pd.DataFrame(similarity_scores_SOI, columns=['filename', 'Similarity SOI'])\n",
    "similarity_SOI.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_SOI\", index=False)\n",
    "\n",
    "similarity_SOI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:43.040206Z",
     "end_time": "2024-05-28T15:14:43.250686Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                              filename  Similarity NR\n0   all_iterations_string_T0.6_280.csv      53.571429\n1  all_iterations_string_T0.6_3441.csv      52.604167\n2  all_iterations_string_T0.6_3644.csv      49.746193\n3  all_iterations_string_T0.6_5991.csv      52.040816\n4  all_iterations_string_T0.6_7917.csv      55.384615\n5     all_iterations_string_T0_280.csv      53.804348\n6    all_iterations_string_T0_3441.csv      52.736318\n7    all_iterations_string_T0_3644.csv      55.778894\n8    all_iterations_string_T0_5991.csv      54.807692\n9    all_iterations_string_T0_7917.csv      56.185567",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity NR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0.6_280.csv</td>\n      <td>53.571429</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0.6_3441.csv</td>\n      <td>52.604167</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0.6_3644.csv</td>\n      <td>49.746193</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0.6_5991.csv</td>\n      <td>52.040816</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0.6_7917.csv</td>\n      <td>55.384615</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>53.804348</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>52.736318</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>55.778894</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>54.807692</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>56.185567</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_NR = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Not relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_NR.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "similarity_NR = pd.DataFrame(similarity_scores_SOI, columns=['filename', 'Similarity NR'])\n",
    "similarity_NR.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_NR\", index=False)\n",
    "\n",
    "similarity_NR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:44.398107Z",
     "end_time": "2024-05-28T15:14:45.006347Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation with context specified in text\n",
    "codebook B1.0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Load codebook - zero shot\n",
    "with open('codebooks/B1.0.1', 'r', encoding='utf-8') as file:\n",
    "    B101 = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T13:49:36.636787Z",
     "end_time": "2024-05-28T13:49:36.666060Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644 - iteration 1\n",
      "3644 - I1 - B39 fingerprint does not match\n",
      "3644 - I1 - B42 fingerprint does not match\n",
      "3644 - I1 - B57 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "3441 - iteration 1\n",
      "3441 - I1 - B3 fingerprint does not match\n",
      "3441 - I1 - B59 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "280 - iteration 1\n",
      "280 - I1 - B12 fingerprint does not match\n",
      "280 - I1 - B33 fingerprint does not match\n",
      "280 - I1 - B46 fingerprint does not match\n",
      "280 - I1 - B56 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "5991 - iteration 1\n",
      "5991 - I1 - B61 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "7917 - iteration 1\n",
      "7917 - I1 - B9 fingerprint does not match\n",
      "7917 - I1 - B37 fingerprint does not match\n",
      "7917 - I1 - B52 fingerprint does not match\n",
      "7917 - I1 - B60 fingerprint does not match\n",
      "iteration:  1 completed\n"
     ]
    }
   ],
   "source": [
    "# Annotate the data - T0 - I1\n",
    "for seed in seeds:\n",
    "    gpt_annotate_string.gpt_annotate(text_to_annotate, B101, key, seed,fingerprint, experiment=\"B1.0.1\",  num_iterations=1, model=\"gpt-4o\", temperature=0, batch_size=20, human_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T13:49:39.749149Z",
     "end_time": "2024-05-28T14:05:34.479365Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation B1.0 with context - B1.0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  similarity ALL\n0   all_iterations_string_T0_280.csv       56.095406\n1  all_iterations_string_T0_3441.csv       54.863481\n2  all_iterations_string_T0_3644.csv       56.163194\n3  all_iterations_string_T0_5991.csv       57.333333\n4  all_iterations_string_T0_7917.csv       56.802120",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>similarity ALL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>56.095406</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>54.863481</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>56.163194</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>57.333333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>56.802120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through each file in the directory\n",
    "directoryB101 = 'STRING_RESULT/B1.0.1/all_iterations'\n",
    "B101similarity_scores_all = []\n",
    "\n",
    "for filename in os.listdir(directoryB101):\n",
    "    file_path = os.path.join(directoryB101, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    Rx = df['RELEVANCE_x']\n",
    "    Ry = df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx, Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B101similarity_scores_all.append((filename, similarity_score))\n",
    "\n",
    "B101similarity_all = pd.DataFrame(B101similarity_scores_all, columns=['filename', 'similarity ALL'])\n",
    "B101similarity_all.to_csv(\"STRING_RESULT/B1.0.1/T0_similarity_scores_all\", index=False)\n",
    "\n",
    "B101similarity_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:14:58.617368Z",
     "end_time": "2024-05-28T15:14:58.854503Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity RELEVANT\n0   all_iterations_string_T0_280.csv            81.463415\n1  all_iterations_string_T0_3441.csv            79.904306\n2  all_iterations_string_T0_3644.csv            83.414634\n3  all_iterations_string_T0_5991.csv            82.488479\n4  all_iterations_string_T0_7917.csv            82.038835",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity RELEVANT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>81.463415</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>79.904306</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>83.414634</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>82.488479</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>82.038835</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B101similarity_scores_relevant = []\n",
    "\n",
    "for filename in os.listdir(directoryB101):\n",
    "    file_path = os.path.join(directoryB101, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B101similarity_scores_relevant.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B101similarity_relevant = pd.DataFrame(B101similarity_scores_relevant, columns=['filename', 'Similarity RELEVANT'])\n",
    "B101similarity_relevant.to_csv(\"STRING_RESULT/B1.0.1/T0_similarity_scores_relevant\", index=False)\n",
    "\n",
    "B101similarity_relevant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:15:00.784146Z",
     "end_time": "2024-05-28T15:15:00.915499Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity SOI\n0   all_iterations_string_T0_280.csv       50.515464\n1  all_iterations_string_T0_3441.csv       54.411765\n2  all_iterations_string_T0_3644.csv       50.246305\n3  all_iterations_string_T0_5991.csv       53.140097\n4  all_iterations_string_T0_7917.csv       53.886010",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity SOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>50.515464</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>54.411765</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>50.246305</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>53.140097</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>53.886010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B101similarity_scores_SOI = []\n",
    "\n",
    "for filename in os.listdir(directoryB101):\n",
    "    file_path = os.path.join(directoryB101, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Statement of intent']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B101similarity_scores_SOI.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B101similarity_SOI = pd.DataFrame(B101similarity_scores_SOI, columns=['filename', 'Similarity SOI'])\n",
    "B101similarity_SOI.to_csv(\"STRING_RESULT/B1.0.1/T0_similarity_scores_SOI\", index=False)\n",
    "\n",
    "B101similarity_SOI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:15:03.975529Z",
     "end_time": "2024-05-28T15:15:04.083235Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity NR\n0   all_iterations_string_T0_280.csv      50.515464\n1  all_iterations_string_T0_3441.csv      54.411765\n2  all_iterations_string_T0_3644.csv      50.246305\n3  all_iterations_string_T0_5991.csv      53.140097\n4  all_iterations_string_T0_7917.csv      53.886010",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity NR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>50.515464</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>54.411765</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>50.246305</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>53.140097</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>53.886010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B101similarity_scores_NR = []\n",
    "\n",
    "for filename in os.listdir(directoryB101):\n",
    "    file_path = os.path.join(directoryB101, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Not relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B101similarity_scores_NR.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B101similarity_NR = pd.DataFrame(B101similarity_scores_SOI, columns=['filename', 'Similarity NR'])\n",
    "B101similarity_NR.to_csv(\"STRING_RESULT/B1.0.1/T0_similarity_scores_NR\", index=False)\n",
    "\n",
    "B101similarity_NR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:09:03.370652Z",
     "end_time": "2024-05-28T15:09:03.605962Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B1.1 - Oneshot codebook\n",
    "Evaluation with T=0 and 1 iteration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# Load codebook - zero shot\n",
    "with open('codebooks/B1.1', 'r', encoding='utf-8') as file:\n",
    "    B11 = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T14:17:41.064119Z",
     "end_time": "2024-05-28T14:17:41.117450Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644 - iteration 1\n",
      "3644 - I1 - B24 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "3441 - iteration 1\n",
      "3441 - I1 - B1 fingerprint does not match\n",
      "3441 - I1 - B15 fingerprint does not match\n",
      "3441 - I1 - B31 fingerprint does not match\n",
      "3441 - I1 - B32 fingerprint does not match\n",
      "3441 - I1 - B46 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "280 - iteration 1\n",
      "280 - I1 - B7 fingerprint does not match\n",
      "280 - I1 - B20 fingerprint does not match\n",
      "280 - I1 - B22 fingerprint does not match\n",
      "280 - I1 - B23 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "5991 - iteration 1\n",
      "5991 - I1 - B1 fingerprint does not match\n",
      "5991 - I1 - B4 fingerprint does not match\n",
      "5991 - I1 - B9 fingerprint does not match\n",
      "5991 - I1 - B20 fingerprint does not match\n",
      "5991 - I1 - B22 fingerprint does not match\n",
      "5991 - I1 - B32 fingerprint does not match\n",
      "5991 - I1 - B35 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "7917 - iteration 1\n",
      "7917 - I1 - B2 fingerprint does not match\n",
      "7917 - I1 - B10 fingerprint does not match\n",
      "7917 - I1 - B18 fingerprint does not match\n",
      "7917 - I1 - B51 fingerprint does not match\n",
      "7917 - I1 - B61 fingerprint does not match\n",
      "iteration:  1 completed\n"
     ]
    }
   ],
   "source": [
    "# Annotate the data - T0 - I1\n",
    "for seed in seeds:\n",
    "    gpt_annotate_string.gpt_annotate(text_to_annotate, B11, key, seed,fingerprint, experiment=\"B1.1\",  num_iterations=1, model=\"gpt-4o\", temperature=0, batch_size=20, human_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T14:18:03.418226Z",
     "end_time": "2024-05-28T14:35:04.471909Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation B1.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  similarity ALL\n0   all_iterations_string_T0_280.csv       64.045936\n1  all_iterations_string_T0_3441.csv       64.478417\n2  all_iterations_string_T0_3644.csv       63.758389\n3  all_iterations_string_T0_5991.csv       63.805970\n4  all_iterations_string_T0_7917.csv       63.392857",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>similarity ALL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>64.045936</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>64.478417</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>63.758389</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>63.805970</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>63.392857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through each file in the directory\n",
    "directoryB11 = 'STRING_RESULT/B1.1/all_iterations'\n",
    "B11similarity_scores_all = []\n",
    "\n",
    "for filename in os.listdir(directoryB11):\n",
    "    file_path = os.path.join(directoryB11, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    Rx = df['RELEVANCE_x']\n",
    "    Ry = df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx, Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B11similarity_scores_all.append((filename, similarity_score))\n",
    "\n",
    "B11similarity_all = pd.DataFrame(B11similarity_scores_all, columns=['filename', 'similarity ALL'])\n",
    "B11similarity_all.to_csv(\"STRING_RESULT/B1.1/T0_similarity_scores_all\", index=False)\n",
    "\n",
    "B11similarity_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:15:20.900819Z",
     "end_time": "2024-05-28T15:15:21.125032Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity RELEVANT\n0   all_iterations_string_T0_280.csv            81.683168\n1  all_iterations_string_T0_3441.csv            81.122449\n2  all_iterations_string_T0_3644.csv            76.497696\n3  all_iterations_string_T0_5991.csv            81.521739\n4  all_iterations_string_T0_7917.csv            80.097087",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity RELEVANT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>81.683168</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>81.122449</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>76.497696</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>81.521739</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>80.097087</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B11similarity_scores_relevant = []\n",
    "\n",
    "for filename in os.listdir(directoryB11):\n",
    "    file_path = os.path.join(directoryB11, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B11similarity_scores_relevant.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B11similarity_relevant = pd.DataFrame(B11similarity_scores_relevant, columns=['filename', 'Similarity RELEVANT'])\n",
    "B11similarity_relevant.to_csv(\"STRING_RESULT/B1.1/T0_similarity_scores_relevant\", index=False)\n",
    "\n",
    "B11similarity_relevant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:15:24.249144Z",
     "end_time": "2024-05-28T15:15:24.359514Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity SOI\n0   all_iterations_string_T0_280.csv       53.513514\n1  all_iterations_string_T0_3441.csv       56.701031\n2  all_iterations_string_T0_3644.csv       57.560976\n3  all_iterations_string_T0_5991.csv       55.307263\n4  all_iterations_string_T0_7917.csv       56.111111",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity SOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>53.513514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>56.701031</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>57.560976</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>55.307263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>56.111111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B11similarity_scores_SOI = []\n",
    "\n",
    "for filename in os.listdir(directoryB11):\n",
    "    file_path = os.path.join(directoryB11, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Statement of intent']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B11similarity_scores_SOI.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B11similarity_SOI = pd.DataFrame(B11similarity_scores_SOI, columns=['filename', 'Similarity SOI'])\n",
    "B11similarity_SOI.to_csv(\"STRING_RESULT/B1.1/T0_similarity_scores_SOI\", index=False)\n",
    "\n",
    "B11similarity_SOI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:15:31.823143Z",
     "end_time": "2024-05-28T15:15:31.937744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity NR\n0   all_iterations_string_T0_280.csv      53.513514\n1  all_iterations_string_T0_3441.csv      56.701031\n2  all_iterations_string_T0_3644.csv      57.560976\n3  all_iterations_string_T0_5991.csv      55.307263\n4  all_iterations_string_T0_7917.csv      56.111111",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity NR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>53.513514</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>56.701031</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>57.560976</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>55.307263</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>56.111111</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B11similarity_scores_NR = []\n",
    "\n",
    "for filename in os.listdir(directoryB11):\n",
    "    file_path = os.path.join(directoryB11, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Not relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B11similarity_scores_NR.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B11similarity_NR = pd.DataFrame(B11similarity_scores_SOI, columns=['filename', 'Similarity NR'])\n",
    "B11similarity_NR.to_csv(\"STRING_RESULT/B1.1/T0_similarity_scores_NR\", index=False)\n",
    "\n",
    "B11similarity_NR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:15:55.053402Z",
     "end_time": "2024-05-28T15:15:55.246512Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B1.1.1 - Oneshot codebook WITH CONTEXT\n",
    "Evaluation with T=0 and 1 iteration\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Load codebook - zero shot\n",
    "with open('codebooks/B1.1.1', 'r', encoding='utf-8') as file:\n",
    "    B111 = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:16:07.609272Z",
     "end_time": "2024-05-28T15:16:07.639671Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3644 - iteration 1\n",
      "iteration:  1 completed\n",
      "3441 - iteration 1\n",
      "3441 - I1 - B4 fingerprint does not match\n",
      "3441 - I1 - B5 fingerprint does not match\n",
      "3441 - I1 - B6 fingerprint does not match\n",
      "3441 - I1 - B27 fingerprint does not match\n",
      "3441 - I1 - B30 fingerprint does not match\n",
      "3441 - I1 - B37 fingerprint does not match\n",
      "3441 - I1 - B45 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "280 - iteration 1\n",
      "280 - I1 - B13 fingerprint does not match\n",
      "280 - I1 - B15 fingerprint does not match\n",
      "280 - I1 - B38 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "5991 - iteration 1\n",
      "5991 - I1 - B59 fingerprint does not match\n",
      "iteration:  1 completed\n",
      "7917 - iteration 1\n",
      "7917 - I1 - B30 fingerprint does not match\n",
      "7917 - I1 - B56 fingerprint does not match\n",
      "iteration:  1 completed\n"
     ]
    }
   ],
   "source": [
    "# Annotate the data - T0 - I1\n",
    "for seed in seeds:\n",
    "    gpt_annotate_string.gpt_annotate(text_to_annotate, B111, key, seed,fingerprint, experiment=\"B1.1.1\",  num_iterations=1, model=\"gpt-4o\", temperature=0, batch_size=20, human_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:16:09.566633Z",
     "end_time": "2024-05-28T15:34:49.180337Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate B111\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  similarity ALL\n0   all_iterations_string_T0_280.csv       62.152778\n1  all_iterations_string_T0_3441.csv       61.692015\n2  all_iterations_string_T0_3644.csv       61.409396\n3  all_iterations_string_T0_5991.csv       62.500000\n4  all_iterations_string_T0_7917.csv       62.201365",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>similarity ALL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>62.152778</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>61.692015</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>61.409396</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>62.500000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>62.201365</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through each file in the directory\n",
    "directoryB111 = 'STRING_RESULT/B1.1.1/all_iterations'\n",
    "B111similarity_scores_all = []\n",
    "\n",
    "for filename in os.listdir(directoryB111):\n",
    "    file_path = os.path.join(directoryB111, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    Rx = df['RELEVANCE_x']\n",
    "    Ry = df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx, Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B111similarity_scores_all.append((filename, similarity_score))\n",
    "\n",
    "B111similarity_all = pd.DataFrame(B111similarity_scores_all, columns=['filename', 'similarity ALL'])\n",
    "B111similarity_all.to_csv(\"STRING_RESULT/B1.1.1/T0_similarity_scores_all\", index=False)\n",
    "\n",
    "B111similarity_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:36:29.531431Z",
     "end_time": "2024-05-28T15:36:29.995174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity RELEVANT\n0   all_iterations_string_T0_280.csv            85.365854\n1  all_iterations_string_T0_3441.csv            85.082873\n2  all_iterations_string_T0_3644.csv            82.547170\n3  all_iterations_string_T0_5991.csv            82.790698\n4  all_iterations_string_T0_7917.csv            81.132075",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity RELEVANT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>85.365854</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>85.082873</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>82.547170</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>82.790698</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>81.132075</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B111similarity_scores_relevant = []\n",
    "\n",
    "for filename in os.listdir(directoryB111):\n",
    "    file_path = os.path.join(directoryB111, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B111similarity_scores_relevant.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B111similarity_relevant = pd.DataFrame(B111similarity_scores_relevant, columns=['filename', 'Similarity RELEVANT'])\n",
    "B111similarity_relevant.to_csv(\"STRING_RESULT/B1.1.1/T0_similarity_scores_relevant\", index=False)\n",
    "\n",
    "B111similarity_relevant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:36:58.559955Z",
     "end_time": "2024-05-28T15:36:58.705570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity SOI\n0   all_iterations_string_T0_280.csv       53.960396\n1  all_iterations_string_T0_3441.csv       51.041667\n2  all_iterations_string_T0_3644.csv       53.140097\n3  all_iterations_string_T0_5991.csv       54.146341\n4  all_iterations_string_T0_7917.csv       55.276382",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity SOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>53.960396</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>51.041667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>53.140097</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>54.146341</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>55.276382</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B111similarity_scores_SOI = []\n",
    "\n",
    "for filename in os.listdir(directoryB111):\n",
    "    file_path = os.path.join(directoryB111, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Statement of intent']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B111similarity_scores_SOI.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B111similarity_SOI = pd.DataFrame(B111similarity_scores_SOI, columns=['filename', 'Similarity SOI'])\n",
    "B111similarity_SOI.to_csv(\"STRING_RESULT/B1.1.1/T0_similarity_scores_SOI\", index=False)\n",
    "\n",
    "B111similarity_SOI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:38:06.639641Z",
     "end_time": "2024-05-28T15:38:06.773981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "                            filename  Similarity NR\n0   all_iterations_string_T0_280.csv      53.960396\n1  all_iterations_string_T0_3441.csv      51.041667\n2  all_iterations_string_T0_3644.csv      53.140097\n3  all_iterations_string_T0_5991.csv      54.146341\n4  all_iterations_string_T0_7917.csv      55.276382",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity NR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_T0_280.csv</td>\n      <td>53.960396</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_T0_3441.csv</td>\n      <td>51.041667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_T0_3644.csv</td>\n      <td>53.140097</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_T0_5991.csv</td>\n      <td>54.146341</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_T0_7917.csv</td>\n      <td>55.276382</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B111similarity_scores_NR = []\n",
    "\n",
    "for filename in os.listdir(directoryB111):\n",
    "    file_path = os.path.join(directoryB111, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Not relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    B111similarity_scores_NR.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "B111similarity_NR = pd.DataFrame(B111similarity_scores_SOI, columns=['filename', 'Similarity NR'])\n",
    "B111similarity_NR.to_csv(\"STRING_RESULT/B1.1.1/T0_similarity_scores_NR\", index=False)\n",
    "\n",
    "B111similarity_NR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T15:38:38.923794Z",
     "end_time": "2024-05-28T15:38:39.178355Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B1.2 - TWOshot codebook\n",
    "Evaluation with T=0 and 1 iteration\n",
    "\n",
    "Codebook is prepared. Currently not evaluated.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
