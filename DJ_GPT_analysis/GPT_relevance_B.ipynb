{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-05-28T10:17:19.605831Z",
     "end_time": "2024-05-28T10:17:19.748864Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook to annotate HLS speeches for relevance\n",
    "### B: string-based labels\n",
    "\n",
    "Codebooks:\n",
    "- B1.0: zero shot\n",
    "- B1.1: one shot\n",
    "- B1.2: two shot\n",
    "\n",
    "- B1.1.1: one shot with specific inclusion of context\n",
    "\n",
    "Test for 5 different seeds\n",
    "Batch of 20 sentences\n",
    "5 iterations\n",
    "\n",
    "Temperature: 0 - 0.2 - 0.6\n",
    "\n",
    "Hypothesis: accuracy decreases with temperature\n",
    "\n",
    "Model selection:\n",
    " As of 22-05-2024, gpt-4-turbo-2024-04-09 seems to be the only gpt-model that returns a fingerprint in addition to gpt-4o\n",
    "\n",
    "  #model= \"gpt-4-turbo-2024-04-09\"\n",
    "  #model = \"gpt-3.5-turbo-0125\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import text to annotate\n",
    "Select only relevant columns of the full dataframe, in this case:\n",
    "RELEVANCE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import string based datafile\n",
    "HLS_train = pd.read_csv('data/string/HLS_train_string.csv', index_col=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T10:16:22.191617Z",
     "end_time": "2024-05-28T10:16:22.376630Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HLS_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### Select only japan for testing purposes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m HLS_train_japan \u001B[38;5;241m=\u001B[39m \u001B[43mHLS_train\u001B[49m[HLS_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCOP19_japan\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m HLS_train\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'HLS_train' is not defined"
     ]
    }
   ],
   "source": [
    "### Select only japan for testing purposes\n",
    "HLS_train_japan = HLS_train[HLS_train['id']=='COP19_japan']\n",
    "HLS_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T10:16:53.319204Z",
     "end_time": "2024-05-28T10:16:53.340632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Select only columns containing relevance labels\n",
    "HLS_relevance = HLS_train_japan[['Text', 'RELEVANCE']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T14:59:02.343854Z",
     "end_time": "2024-05-27T14:59:02.355665Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import necessary files\n",
    "- codebooks\n",
    "- API key\n",
    "- import gpt_annotate_num"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Load codebook - zero shot\n",
    "with open('codebooks/B1.0', 'r', encoding='utf-8') as file:\n",
    "    B10 = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T14:59:02.349016Z",
     "end_time": "2024-05-27T14:59:02.355665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# OpenAI key\n",
    "with open('gpt_api_key.txt', 'r') as f:\n",
    "    key = f.read().strip()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T14:59:02.355665Z",
     "end_time": "2024-05-27T14:59:02.366492Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import gpt_annotate_string"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T14:59:02.366492Z",
     "end_time": "2024-05-27T14:59:16.596637Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for annotation\n",
    "Compares column names in HLS_relevance to the codes identified by GPT-4o in the codebook. Seed for this identification is set to 1234."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9TUEWFOtD82al8mXP98GEjaK0ItAx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='RELEVANCE', role='assistant', function_call=None, tool_calls=None))], created=1716814756, model='gpt-4o-2024-05-13', object='chat.completion', system_fingerprint='fp_43dfabdef1', usage=CompletionUsage(completion_tokens=3, prompt_tokens=332, total_tokens=335))\n",
      "\n",
      "Categories to annotate:\n",
      "1) RELEVANCE\n",
      "\n",
      "\n",
      "Data is ready to be annotated using gpt_annotate()!\n",
      "\n",
      "Glimpse of your data:\n",
      "Shape of data:  (37, 4)\n",
      "   unique_id                                               text  \\\n",
      "0          0                         Thank you, Mr. President .   \n",
      "1          1   On beha lf of the government of Japan , I wou...   \n",
      "2          2   I would also like to expr ess my d eepest con...   \n",
      "3          3   Mr. President:  A fair and effective framewor...   \n",
      "4          4   In this regard, Japan firmly supports the est...   \n",
      "\n",
      "             RELEVANCE                                          llm_query  \n",
      "0         Not relevant                    0  Thank you, Mr. President .\\n  \n",
      "1         Not relevant  1  On beha lf of the government of Japan , I w...  \n",
      "2         Not relevant  2  I would also like to expr ess my d eepest c...  \n",
      "3             Relevant  3  Mr. President:  A fair and effective framew...  \n",
      "4  Statement of intent  4  In this regard, Japan firmly supports the e...  \n"
     ]
    }
   ],
   "source": [
    "# Prepare dataframe for annotation\n",
    "text_to_annotate = gpt_annotate_string.prepare_data(HLS_relevance, B10, key, prep_codebook=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T14:59:16.601083Z",
     "end_time": "2024-05-27T14:59:20.250254Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fingerprint used: fp_43dfabdef1\n",
    "\n",
    "Seed of textpreparation is hardcoded into gpt_annotate. This to ensure that onlye the results of the same fingerprint for all seeds and all iterations. Essentially every time GPT-4o is called only results with this specific fingerprint are saved."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Run gpt_annotate_num\n",
    "Evaluation per seed -\n",
    "5 different seeds\n",
    "Batch of 20 sentences\n",
    "5 iterations\n",
    "\n",
    "Returns 2 outputs per seed;\n",
    "1. all_iterations_{seed}.csv\n",
    "2. fingerprints_all.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "fingerprint = 'fp_43dfabdef1'\n",
    "seeds = [3644,3441, 280, 5991, 7917]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T14:59:20.243410Z",
     "end_time": "2024-05-27T14:59:20.250254Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 3644: Iteration 1, batch 1: fingerprintmatch found!\n",
      "Seed: 3644: Iteration 1, batch 2: fingerprintmatch found!\n",
      "iteration:  1 completed\n",
      "Seed: 3644: Iteration 2, batch 1: fingerprintmatch found!\n",
      "Seed: 3644: Iteration 2, batch 2: fingerprintmatch found!\n",
      "iteration:  2 completed\n",
      "Seed: 3644: Iteration 3, batch 1: fingerprintmatch found!\n",
      "Seed: 3644: Iteration 3, batch 2: fingerprintmatch found!\n",
      "iteration:  3 completed\n",
      "Seed: 3644: Iteration 4, batch 1: fingerprintmatch found!\n",
      "Seed: 3644: Iteration 4, batch 2: fingerprintmatch found!\n",
      "iteration:  4 completed\n",
      "Seed: 3644: Iteration 5, batch 1: fingerprintmatch found!\n",
      "Seed: 3644: Iteration 5, batch 2: fingerprintmatch found!\n",
      "iteration:  5 completed\n",
      "Seed: 3441: Iteration 1, batch 1: fingerprintmatch found!\n",
      "Seed: 3441: Iteration 1, batch 2: fingerprintmatch found!\n",
      "iteration:  1 completed\n",
      "Seed: 3441: Iteration 2, batch 1: fingerprintmatch found!\n",
      "Seed: 3441: Iteration 2, batch 2: fingerprintmatch found!\n",
      "iteration:  2 completed\n",
      "Seed: 3441: Iteration 3, batch 1: fingerprintmatch found!\n",
      "Seed: 3441: Iteration 3, batch 2: fingerprintmatch found!\n",
      "iteration:  3 completed\n",
      "Seed: 3441: Iteration 4, batch 1: fingerprintmatch found!\n",
      "Seed: 3441: Iteration 4, batch 2: fingerprintmatch found!\n",
      "iteration:  4 completed\n",
      "Seed: 3441: Iteration 5, batch 1: fingerprintmatch found!\n",
      "Seed: 3441: Iteration 5, batch 2: fingerprintmatch found!\n",
      "iteration:  5 completed\n",
      "Seed: 280: Iteration 1, batch 1: fingerprintmatch found!\n",
      "Seed: 280: Iteration 1, batch 2: fingerprintmatch found!\n",
      "iteration:  1 completed\n",
      "Seed: 280: Iteration 2, batch 1: fingerprintmatch found!\n",
      "Seed: 280: Iteration 2, batch 2: fingerprintmatch found!\n",
      "iteration:  2 completed\n",
      "Seed: 280: Iteration 3, batch 1: fingerprintmatch found!\n",
      "Seed: 280: Iteration 3, batch 2: fingerprintmatch found!\n",
      "iteration:  3 completed\n",
      "Seed: 280: Iteration 4, batch 1: fingerprintmatch found!\n",
      "Seed: 280: Iteration 4, batch 2: fingerprintmatch found!\n",
      "iteration:  4 completed\n",
      "Seed: 280: Iteration 5, batch 1: fingerprintmatch found!\n",
      "Seed: 280: Iteration 5, batch 2: fingerprintmatch found!\n",
      "iteration:  5 completed\n",
      "Seed: 5991: Iteration 1, batch 1: fingerprintmatch found!\n",
      "Seed: 5991: Iteration 1, batch 2: fingerprintmatch found!\n",
      "iteration:  1 completed\n",
      "Seed: 5991: Iteration 2, batch 1: fingerprintmatch found!\n",
      "Seed: 5991: Iteration 2, batch 2: fingerprintmatch found!\n",
      "iteration:  2 completed\n",
      "Seed: 5991: Iteration 3, batch 1: fingerprintmatch found!\n",
      "Seed: 5991: Iteration 3, batch 2: fingerprintmatch found!\n",
      "iteration:  3 completed\n",
      "Seed: 5991: Iteration 4, batch 1: fingerprintmatch found!\n",
      "Seed: 5991: Iteration 4, batch 2: fingerprintmatch found!\n",
      "iteration:  4 completed\n",
      "Seed: 5991: Iteration 5, batch 1: fingerprintmatch found!\n",
      "Seed: 5991: Iteration 5, batch 2: fingerprintmatch found!\n",
      "iteration:  5 completed\n",
      "Seed: 7917: Iteration 1, batch 1: fingerprintmatch found!\n",
      "Seed: 7917: Iteration 1, batch 2: fingerprintmatch found!\n",
      "iteration:  1 completed\n",
      "Seed: 7917: Iteration 2, batch 1: fingerprintmatch found!\n",
      "Seed: 7917: Iteration 2, batch 2: fingerprintmatch found!\n",
      "iteration:  2 completed\n",
      "Seed: 7917: Iteration 3, batch 1: fingerprintmatch found!\n",
      "Seed: 7917: Iteration 3, batch 2: fingerprintmatch found!\n",
      "iteration:  3 completed\n",
      "Seed: 7917: Iteration 4, batch 1: fingerprintmatch found!\n",
      "Seed: 7917: Iteration 4, batch 2: fingerprintmatch found!\n",
      "iteration:  4 completed\n",
      "Seed: 7917: Iteration 5, batch 1: fingerprintmatch found!\n",
      "Seed: 7917: Iteration 5, batch 2: fingerprintmatch found!\n",
      "iteration:  5 completed\n"
     ]
    }
   ],
   "source": [
    "# Annotate the data - T0\n",
    "for seed in seeds:\n",
    "    gpt_annotate_string.gpt_annotate(text_to_annotate, B10, key, seed,fingerprint, experiment=\"B1.0\",  num_iterations=5, model=\"gpt-4o\", temperature=0, batch_size=20, human_labels=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T15:01:30.760657Z",
     "end_time": "2024-05-27T15:04:17.820857Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gpt_annotate_string.gpt_annotate(text_to_annotate, B10, key, fingerprint, seed,experiment='B1.0', num_iterations=5, model=\"gpt-4o\", batch_size=20, human_labels=True, time_cost_warning=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate accuracy of predictions\n",
    "Based on similarity between predicted and true labels.\n",
    "Currently not taking consistency into account - would be done by grouping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_similarity_score(Rx, Ry):\n",
    "    # Ensure Rx and Ry are pandas Series and convert to strings with stripped whitespace\n",
    "    Rx = Rx.astype(str).str.strip()\n",
    "    Ry = Ry.astype(str).str.strip()\n",
    "\n",
    "    # Calculate similarity scores\n",
    "    similarity_scores = Rx.combine(Ry, lambda x, y: difflib.SequenceMatcher(None, x, y).ratio())\n",
    "\n",
    "    # Apply the threshold - maybe put higher?\n",
    "    similarity_scores = similarity_scores.apply(lambda x: x if x >= 0.9 else 0)\n",
    "\n",
    "    # Return the mean similarity score as a percentage\n",
    "    return similarity_scores.mean() * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T15:48:03.116467Z",
     "end_time": "2024-05-27T15:48:03.130611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                         filename  similarity ALL\n0   all_iterations_string_280.csv       75.263158\n1  all_iterations_string_3441.csv       75.789474\n2  all_iterations_string_3644.csv       76.842105\n3  all_iterations_string_5991.csv       75.263158\n4  all_iterations_string_7917.csv       78.421053",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>similarity ALL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_280.csv</td>\n      <td>75.263158</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_3441.csv</td>\n      <td>75.789474</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_3644.csv</td>\n      <td>76.842105</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_5991.csv</td>\n      <td>75.263158</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_7917.csv</td>\n      <td>78.421053</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through each file in the directory\n",
    "directory = 'STRING_RESULT/B1.0/all_iterations'\n",
    "similarity_scores_all = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    Rx = df['RELEVANCE_x']\n",
    "    Ry = df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_all.append((filename, similarity_score))\n",
    "\n",
    "similarity_all = pd.DataFrame(similarity_scores_all, columns=['filename', 'similarity ALL'])\n",
    "similarity_all.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_all\", index=False)\n",
    "\n",
    "similarity_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T15:48:07.154568Z",
     "end_time": "2024-05-27T15:48:07.244056Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                         filename  Similarity RELEVANT\n0   all_iterations_string_280.csv                100.0\n1  all_iterations_string_3441.csv                100.0\n2  all_iterations_string_3644.csv                100.0\n3  all_iterations_string_5991.csv                 90.0\n4  all_iterations_string_7917.csv                100.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity RELEVANT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_280.csv</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_3441.csv</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_3644.csv</td>\n      <td>100.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_5991.csv</td>\n      <td>90.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_7917.csv</td>\n      <td>100.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_relevant = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_relevant.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "similarity_relevant = pd.DataFrame(similarity_scores_relevant, columns=['filename', 'Similarity RELEVANT'])\n",
    "similarity_relevant.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_relevant\", index=False)\n",
    "\n",
    "similarity_relevant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T15:48:11.593772Z",
     "end_time": "2024-05-27T15:48:11.683574Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                         filename  Similarity SOI\n0   all_iterations_string_280.csv       72.631579\n1  all_iterations_string_3441.csv       73.684211\n2  all_iterations_string_3644.csv       72.631579\n3  all_iterations_string_5991.csv       71.578947\n4  all_iterations_string_7917.csv       83.157895",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity SOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_280.csv</td>\n      <td>72.631579</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_3441.csv</td>\n      <td>73.684211</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_3644.csv</td>\n      <td>72.631579</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_5991.csv</td>\n      <td>71.578947</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_7917.csv</td>\n      <td>83.157895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_SOI = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Statement of intent']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_SOI.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "similarity_SOI = pd.DataFrame(similarity_scores_SOI, columns=['filename', 'Similarity SOI'])\n",
    "similarity_SOI.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_SOI\", index=False)\n",
    "\n",
    "similarity_SOI"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T15:49:42.139013Z",
     "end_time": "2024-05-27T15:49:42.219909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                         filename  Similarity SOI\n0   all_iterations_string_280.csv       72.631579\n1  all_iterations_string_3441.csv       73.684211\n2  all_iterations_string_3644.csv       72.631579\n3  all_iterations_string_5991.csv       71.578947\n4  all_iterations_string_7917.csv       83.157895",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Similarity SOI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all_iterations_string_280.csv</td>\n      <td>72.631579</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>all_iterations_string_3441.csv</td>\n      <td>73.684211</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>all_iterations_string_3644.csv</td>\n      <td>72.631579</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>all_iterations_string_5991.csv</td>\n      <td>71.578947</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>all_iterations_string_7917.csv</td>\n      <td>83.157895</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores_NR = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    relevant_df = df[df['RELEVANCE_x'] == 'Not relevant']\n",
    "\n",
    "    Rx = relevant_df['RELEVANCE_x']\n",
    "    Ry = relevant_df['RELEVANCE_y']\n",
    "\n",
    "    similarity_score = get_similarity_score(Rx,Ry)\n",
    "\n",
    "    #Save the score in a dataframe\n",
    "    similarity_scores_NR.append((filename, similarity_score))\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "similarity_NR = pd.DataFrame(similarity_scores_SOI, columns=['filename', 'Similarity SOI'])\n",
    "similarity_NR.to_csv(\"STRING_RESULT/B1.0/T0_similarity_scores_NR\", index=False)\n",
    "\n",
    "similarity_NR"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-27T15:53:41.597723Z",
     "end_time": "2024-05-27T15:53:41.651220Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate all sentences\n",
    "Get insights into full prediction. See where there are inconsistencies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     unique_id                                 text   RELEVANCE_x  \\\n0            0           Thank you, Mr. President .  Not relevant   \n1            0           Thank you, Mr. President .  Not relevant   \n2            0           Thank you, Mr. President .  Not relevant   \n3            0           Thank you, Mr. President .  Not relevant   \n4            0           Thank you, Mr. President .  Not relevant   \n..         ...                                  ...           ...   \n185         36   Thank you for your kind attention.  Not relevant   \n186         36   Thank you for your kind attention.  Not relevant   \n187         36   Thank you for your kind attention.  Not relevant   \n188         36   Thank you for your kind attention.  Not relevant   \n189         36   Thank you for your kind attention.  Not relevant   \n\n                                    llm_query   RELEVANCE_y  iteration  \n0             0  Thank you, Mr. President .\\n  Not relevant          1  \n1             0  Thank you, Mr. President .\\n  Not relevant          2  \n2             0  Thank you, Mr. President .\\n  Not relevant          3  \n3             0  Thank you, Mr. President .\\n  Not relevant          4  \n4             0  Thank you, Mr. President .\\n  Not relevant          5  \n..                                        ...           ...        ...  \n185  36  Thank you for your kind attention.\\n  Not relevant          1  \n186  36  Thank you for your kind attention.\\n  Not relevant          2  \n187  36  Thank you for your kind attention.\\n  Not relevant          3  \n188  36  Thank you for your kind attention.\\n  Not relevant          4  \n189  36  Thank you for your kind attention.\\n  Not relevant          5  \n\n[190 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>text</th>\n      <th>RELEVANCE_x</th>\n      <th>llm_query</th>\n      <th>RELEVANCE_y</th>\n      <th>iteration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Thank you, Mr. President .</td>\n      <td>Not relevant</td>\n      <td>0  Thank you, Mr. President .\\n</td>\n      <td>Not relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Thank you, Mr. President .</td>\n      <td>Not relevant</td>\n      <td>0  Thank you, Mr. President .\\n</td>\n      <td>Not relevant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Thank you, Mr. President .</td>\n      <td>Not relevant</td>\n      <td>0  Thank you, Mr. President .\\n</td>\n      <td>Not relevant</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Thank you, Mr. President .</td>\n      <td>Not relevant</td>\n      <td>0  Thank you, Mr. President .\\n</td>\n      <td>Not relevant</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Thank you, Mr. President .</td>\n      <td>Not relevant</td>\n      <td>0  Thank you, Mr. President .\\n</td>\n      <td>Not relevant</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>36</td>\n      <td>Thank you for your kind attention.</td>\n      <td>Not relevant</td>\n      <td>36  Thank you for your kind attention.\\n</td>\n      <td>Not relevant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>186</th>\n      <td>36</td>\n      <td>Thank you for your kind attention.</td>\n      <td>Not relevant</td>\n      <td>36  Thank you for your kind attention.\\n</td>\n      <td>Not relevant</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>187</th>\n      <td>36</td>\n      <td>Thank you for your kind attention.</td>\n      <td>Not relevant</td>\n      <td>36  Thank you for your kind attention.\\n</td>\n      <td>Not relevant</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>188</th>\n      <td>36</td>\n      <td>Thank you for your kind attention.</td>\n      <td>Not relevant</td>\n      <td>36  Thank you for your kind attention.\\n</td>\n      <td>Not relevant</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>36</td>\n      <td>Thank you for your kind attention.</td>\n      <td>Not relevant</td>\n      <td>36  Thank you for your kind attention.\\n</td>\n      <td>Not relevant</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>190 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full280 = pd.read_csv('STRING_RESULT/B1.0/all_iterations/all_iterations_string_280.csv')\n",
    "\n",
    "full280"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-28T09:03:01.638367Z",
     "end_time": "2024-05-28T09:03:01.906537Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
